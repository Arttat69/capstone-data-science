{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-26T14:25:26.888747Z",
     "start_time": "2025-11-26T14:25:19.633529Z"
    }
   },
   "source": [
    "# Enhanced LSTM Commodity Forecasting - FIXED VERSION\n",
    "# Handles missing enrichment data and provides proper backtesting\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "ROOT = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "ENRICHED_DIR = os.path.join(DATA_DIR, \"enriched\")\n",
    "MODEL_RESULTS_DIR = os.path.join(DATA_DIR, 'model_results')\n",
    "os.makedirs(MODEL_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "commodities = [\"Gold\", \"WTI\", \"Wheat\", \"NaturalGas\", \"Copper\", \"Lithium\"]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T14:25:29.374001Z",
     "start_time": "2025-11-26T14:25:29.352474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def create_sequences(data, feature_cols, target_col, seq_length):\n",
    "    \"\"\"Create sequences for LSTM - fixed to use iloc consistently\"\"\"\n",
    "    xs, ys = [], []\n",
    "    data_reset = data.reset_index(drop=True)  # Reset index to avoid issues\n",
    "\n",
    "    for i in range(len(data_reset) - seq_length):\n",
    "        x = data_reset[feature_cols].iloc[i:i+seq_length].values\n",
    "        y = data_reset[target_col].iloc[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def compute_max_drawdown(returns):\n",
    "    \"\"\"Calculate maximum drawdown\"\"\"\n",
    "    cumulative = np.cumprod(1 + returns)\n",
    "    running_max = np.maximum.accumulate(cumulative)\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    return np.min(drawdown)\n",
    "\n",
    "def backtest_volatility_strategy(vol_pred, vol_actual, returns, transaction_cost=0.001):\n",
    "    \"\"\"Trading strategy based on volatility predictions\"\"\"\n",
    "    high_vol_threshold = np.percentile(vol_pred, 75)\n",
    "    low_vol_threshold = np.percentile(vol_pred, 25)\n",
    "\n",
    "    signals = np.zeros(len(vol_pred))\n",
    "    signals[vol_pred > high_vol_threshold] = -0.5\n",
    "    signals[vol_pred < low_vol_threshold] = 1.0\n",
    "    signals[(vol_pred >= low_vol_threshold) & (vol_pred <= high_vol_threshold)] = 0.5\n",
    "\n",
    "    # Align returns\n",
    "    aligned_returns = returns[1:len(signals)+1]\n",
    "    signals = signals[:len(aligned_returns)]\n",
    "\n",
    "    strategy_returns = signals * aligned_returns\n",
    "    position_changes = np.abs(np.diff(np.concatenate([[0], signals])))\n",
    "    transaction_costs = position_changes * transaction_cost\n",
    "    strategy_returns = strategy_returns - transaction_costs[:len(strategy_returns)]\n",
    "\n",
    "    sharpe = np.mean(strategy_returns) / (np.std(strategy_returns) + 1e-10) * np.sqrt(252)\n",
    "    cumulative_return = np.prod(1 + strategy_returns) - 1\n",
    "    max_dd = compute_max_drawdown(strategy_returns)\n",
    "    win_rate = np.mean(strategy_returns > 0)\n",
    "\n",
    "    bh_returns = aligned_returns\n",
    "    bh_sharpe = np.mean(bh_returns) / (np.std(bh_returns) + 1e-10) * np.sqrt(252)\n",
    "\n",
    "    return {\n",
    "        'sharpe': sharpe,\n",
    "        'cumulative_return': cumulative_return * 100,\n",
    "        'max_drawdown': max_dd * 100,\n",
    "        'win_rate': win_rate * 100,\n",
    "        'bh_sharpe': bh_sharpe,\n",
    "        'alpha': sharpe - bh_sharpe,\n",
    "        'avg_return_pct': np.mean(strategy_returns) * 100,\n",
    "        'volatility': np.std(strategy_returns) * 100\n",
    "    }\n",
    "\n",
    "def build_robust_lstm(input_shape):\n",
    "    \"\"\"Build LSTM with regularization\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        LSTM(32, return_sequences=True, kernel_regularizer=l1_l2(l1=0.0001, l2=0.001)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(16, kernel_regularizer=l1_l2(l1=0.0001, l2=0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def plot_results(commodity, y_true, y_pred, returns, history, use_gprd):\n",
    "    \"\"\"Visualization with error handling\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'{commodity} - LSTM Results (GPRD: {\"ON\" if use_gprd else \"OFF\"})', fontsize=16)\n",
    "\n",
    "    # Plot 1: Predictions vs Actual\n",
    "    plot_range = min(200, len(y_true))\n",
    "    axes[0, 0].plot(y_true[-plot_range:], label='Actual Vol', alpha=0.7, linewidth=2)\n",
    "    axes[0, 0].plot(y_pred[-plot_range:], label='Predicted Vol', alpha=0.7, linewidth=2)\n",
    "    axes[0, 0].set_title(f'Volatility Forecast (Last {plot_range} days)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "    # Plot 2: Training history\n",
    "    axes[0, 1].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0, 1].set_title('Training History')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "    # Plot 3: Residuals\n",
    "    residuals = y_true - y_pred\n",
    "    axes[1, 0].scatter(y_pred, residuals, alpha=0.3)\n",
    "    axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[1, 0].set_title('Residual Plot')\n",
    "    axes[1, 0].set_xlabel('Predicted')\n",
    "    axes[1, 0].set_ylabel('Residuals')\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "    # Plot 4: Distribution comparison (with error handling)\n",
    "    try:\n",
    "        # Auto-calculate bins based on data range\n",
    "        n_bins = min(30, max(10, int(len(y_true) / 50)))\n",
    "        axes[1, 1].hist(y_true, bins=n_bins, alpha=0.5, label='Actual', density=True)\n",
    "        axes[1, 1].hist(y_pred, bins=n_bins, alpha=0.5, label='Predicted', density=True)\n",
    "        axes[1, 1].set_title('Distribution Comparison')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(alpha=0.3)\n",
    "    except Exception as e:\n",
    "        # If histogram fails, plot KDE instead\n",
    "        axes[1, 1].text(0.5, 0.5, f'Distribution plot unavailable\\n({str(e)[:50]})',\n",
    "                       ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Distribution Comparison')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_RESULTS_DIR, f'{commodity}_lstm_{\"gprd\" if use_gprd else \"nogprd\"}.png'), dpi=150)\n",
    "    plt.close()\n"
   ],
   "id": "c82fc627050e97ed",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T14:25:30.889893Z",
     "start_time": "2025-11-26T14:25:30.868076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# MAIN MODELING PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def run_enhanced_lstm_with_gprd(commodity_name, df, use_gprd=True):\n",
    "    \"\"\"Run LSTM with optional GPRD integration\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing: {commodity_name} (GPRD: {'ON' if use_gprd else 'OFF'})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    df = df.copy().sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Find and rename Close column\n",
    "    close_col = None\n",
    "    for col in df.columns:\n",
    "        if 'Close' in col or 'close' in col:\n",
    "            close_col = col\n",
    "            break\n",
    "\n",
    "    if close_col is None:\n",
    "        print(f\"ERROR: No Close column found\")\n",
    "        return None\n",
    "\n",
    "    if close_col != 'Close':\n",
    "        df['Close'] = df[close_col]\n",
    "\n",
    "    # Calculate basic features\n",
    "    if 'Return' not in df.columns:\n",
    "        df['Return'] = df['Close'].pct_change()\n",
    "\n",
    "    if 'Vol_5' not in df.columns:\n",
    "        df['Vol_5'] = df['Return'].rolling(5).std()\n",
    "\n",
    "    # ============= NEW: GPRD FEATURE ENGINEERING =============\n",
    "    # Base features to lag\n",
    "    base_features = ['Return', 'Vol_5']\n",
    "\n",
    "    # Add GPRD features if available and user requests them\n",
    "    gprd_features = []\n",
    "    if use_gprd:\n",
    "        if 'GPRD' in df.columns:\n",
    "            df['GPRD'].fillna(method='ffill', inplace=True)\n",
    "            df['GPRD'].fillna(0, inplace=True)\n",
    "\n",
    "            # SIMPLIFIED: Only use 2 most important GPRD features to save memory\n",
    "            df['GPRD_ma5'] = df['GPRD'].rolling(5).mean()\n",
    "            df['GPRD_high_regime'] = (df['GPRD'] > df['GPRD'].rolling(60).quantile(0.75)).astype(int)\n",
    "\n",
    "            gprd_features = ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
    "            print(f\"  Added GPRD features: {gprd_features}\")\n",
    "\n",
    "        if 'geo_keyword_hits' in df.columns:\n",
    "            df['geo_keyword_hits'].fillna(0, inplace=True)\n",
    "            gprd_features.append('geo_keyword_hits')\n",
    "\n",
    "        if 'sentiment' in df.columns:\n",
    "            df['sentiment'].fillna(0, inplace=True)\n",
    "            gprd_features.append('sentiment')\n",
    "\n",
    "    # Combine all features to lag\n",
    "    features_to_lag = base_features + gprd_features\n",
    "\n",
    "    # REDUCED LAG DEPTH: Only lag 1-3 instead of 1-5 to save memory\n",
    "    max_lag = 3\n",
    "    for feat in features_to_lag:\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            df[f'{feat}_lag{lag}'] = df[feat].shift(lag)\n",
    "\n",
    "    # Build feature column list\n",
    "    feature_cols = []\n",
    "    for feat in features_to_lag:\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            feature_cols.append(f'{feat}_lag{lag}')\n",
    "\n",
    "    print(f\"  Total features: {len(feature_cols)} ({'with GPRD' if use_gprd else 'baseline'})\")\n",
    "\n",
    "    # Clean data\n",
    "    required_cols = ['Date', 'Vol_5', 'Return'] + feature_cols\n",
    "    df_clean = df[required_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "    print(f\"Clean data: {len(df_clean)} rows, {len(feature_cols)} features\")\n",
    "\n",
    "    if len(df_clean) < 100:\n",
    "        print(\"Insufficient data\")\n",
    "        return None\n",
    "\n",
    "    # Train/test split\n",
    "    split_idx = int(len(df_clean) * 0.8)\n",
    "    train_df = df_clean.iloc[:split_idx].copy()\n",
    "    test_df = df_clean.iloc[split_idx:].copy()\n",
    "\n",
    "    print(f\"Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "    if len(train_df) < 50 or len(test_df) < 20:\n",
    "        print(\"Insufficient train/test data\")\n",
    "        return None\n",
    "\n",
    "    # Scale features\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    X_train = train_df[feature_cols].values\n",
    "    X_test = test_df[feature_cols].values\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Rebuild as DataFrames\n",
    "    train_scaled = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "    test_scaled = pd.DataFrame(X_test_scaled, columns=feature_cols)\n",
    "\n",
    "    train_scaled['Vol_5'] = train_df['Vol_5'].values\n",
    "    test_scaled['Vol_5'] = test_df['Vol_5'].values\n",
    "    train_scaled['Return'] = train_df['Return'].values\n",
    "    test_scaled['Return'] = test_df['Return'].values\n",
    "\n",
    "    # Create sequences\n",
    "    seq_length = 15  # Reduced from 20 to save memory\n",
    "    X_train_seq, y_train_seq = create_sequences(train_scaled, feature_cols, 'Vol_5', seq_length)\n",
    "    X_test_seq, y_test_seq = create_sequences(test_scaled, feature_cols, 'Vol_5', seq_length)\n",
    "\n",
    "    print(f\"Sequences - Train: {X_train_seq.shape} | Test: {X_test_seq.shape}\")\n",
    "\n",
    "    if len(X_train_seq) < 20 or len(X_test_seq) < 5:\n",
    "        print(\"Insufficient sequences\")\n",
    "        return None\n",
    "\n",
    "    # Build model with adjusted size for more features\n",
    "    if len(feature_cols) > 15:\n",
    "        # Smaller network for high-dimensional input\n",
    "        model = Sequential([\n",
    "            Input(shape=(seq_length, len(feature_cols))),\n",
    "            LSTM(24, kernel_regularizer=l1_l2(l1=0.0001, l2=0.001)),\n",
    "            Dropout(0.2),\n",
    "            Dense(8, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "    else:\n",
    "        model = build_robust_lstm(input_shape=(seq_length, len(feature_cols)))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber', metrics=['mae'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=0)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, verbose=0)\n",
    "\n",
    "    # Reduced batch size for memory efficiency\n",
    "    batch_size = 32 if len(feature_cols) > 15 else 64\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        epochs=100,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train_seq, verbose=0).squeeze()\n",
    "    y_pred_test = model.predict(X_test_seq, verbose=0).squeeze()\n",
    "\n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train_seq, y_pred_train)\n",
    "    test_r2 = r2_score(y_test_seq, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_seq, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test_seq, y_pred_test)\n",
    "\n",
    "    print(f\"Train R²: {train_r2:.4f} | Test R²: {test_r2:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f} | MAE: {test_mae:.4f}\")\n",
    "\n",
    "    # Backtest\n",
    "    test_returns = test_scaled['Return'].iloc[seq_length:].values\n",
    "    backtest_results = backtest_volatility_strategy(y_pred_test, y_test_seq, test_returns)\n",
    "\n",
    "    print(f\"Sharpe: {backtest_results['sharpe']:.3f} | Alpha: {backtest_results['alpha']:.3f}\")\n",
    "    print(f\"Cum Return: {backtest_results['cumulative_return']:.2f}% | Max DD: {backtest_results['max_drawdown']:.2f}%\")\n",
    "\n",
    "    results = {\n",
    "        'commodity': commodity_name,\n",
    "        'use_gprd': use_gprd,\n",
    "        'n_features': len(feature_cols),\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        **backtest_results\n",
    "    }\n",
    "\n",
    "    plot_results(commodity_name, y_test_seq, y_pred_test, test_returns, history, use_gprd)\n",
    "\n",
    "    return results\n"
   ],
   "id": "a14602c53d4a176d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T16:46:16.430312Z",
     "start_time": "2025-11-23T16:36:13.813632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# RUN EXPERIMENTS\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading enriched data...\")\n",
    "    merged_data = {}\n",
    "\n",
    "    for name in commodities:\n",
    "        fname = f\"{name.lower()}_enriched.csv\"\n",
    "        path = os.path.join(ENRICHED_DIR, fname)\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            merged_data[name] = df\n",
    "            # Show ALL columns to verify GPRD is present\n",
    "            has_gprd = 'GPRD' in df.columns\n",
    "            print(f\"  Loaded {name}: {len(df)} rows | GPRD: {'✓' if has_gprd else '✗'} | Cols: {len(df.columns)}\")\n",
    "        else:\n",
    "            print(f\"  Missing: {name}\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for commodity in merged_data.keys():\n",
    "        # Run WITHOUT GPRD (baseline)\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"BASELINE RUN: {commodity} (no GPRD)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        results_no_gprd = run_enhanced_lstm_with_gprd(commodity, merged_data[commodity], use_gprd=False)\n",
    "        if results_no_gprd:\n",
    "            all_results.append(results_no_gprd)\n",
    "\n",
    "        # Run WITH GPRD (if available)\n",
    "        if 'GPRD' in merged_data[commodity].columns:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"ENHANCED RUN: {commodity} (with GPRD)\")\n",
    "            print(f\"{'='*80}\")\n",
    "            results_with_gprd = run_enhanced_lstm_with_gprd(commodity, merged_data[commodity], use_gprd=True)\n",
    "            if results_with_gprd:\n",
    "                all_results.append(results_with_gprd)\n",
    "        else:\n",
    "            print(f\"  Skipping GPRD test for {commodity} - no GPRD column found\")\n",
    "\n",
    "    # Save results\n",
    "    if len(all_results) > 0:\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        results_df.to_csv(os.path.join(MODEL_RESULTS_DIR, 'lstm_gprd_comparison.csv'), index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY: GPRD Impact Analysis\")\n",
    "        print(\"=\"*80)\n",
    "        print(results_df[['commodity', 'use_gprd', 'n_features', 'test_r2', 'sharpe', 'alpha', 'cumulative_return']])\n",
    "\n",
    "        # Compare performance by GPRD usage\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Average Performance: WITH vs WITHOUT GPRD\")\n",
    "        print(\"=\"*80)\n",
    "        comparison = results_df.groupby('use_gprd')[['test_r2', 'sharpe', 'alpha', 'cumulative_return']].mean()\n",
    "        print(comparison)\n",
    "\n",
    "        # Show improvement per commodity\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GPRD Improvement by Commodity\")\n",
    "        print(\"=\"*80)\n",
    "        for commodity in results_df['commodity'].unique():\n",
    "            subset = results_df[results_df['commodity'] == commodity]\n",
    "            if len(subset) == 2:  # Has both baseline and GPRD\n",
    "                baseline = subset[subset['use_gprd'] == False].iloc[0]\n",
    "                gprd = subset[subset['use_gprd'] == True].iloc[0]\n",
    "                sharpe_improvement = gprd['sharpe'] - baseline['sharpe']\n",
    "                print(f\"{commodity:12s}: Sharpe {baseline['sharpe']:.3f} → {gprd['sharpe']:.3f} \"\n",
    "                      f\"({'↑' if sharpe_improvement > 0 else '↓'} {abs(sharpe_improvement):.3f})\")\n",
    "    else:\n",
    "        print(\"\\nNo successful results to save!\")"
   ],
   "id": "8f907dca9f7cf6c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading enriched data...\n",
      "  Loaded Gold: 5342 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded WTI: 5351 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded Wheat: 5367 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded NaturalGas: 3694 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded Copper: 5346 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded Lithium: 2871 rows | GPRD: ✓ | Cols: 17\n",
      "\n",
      "================================================================================\n",
      "BASELINE RUN: Gold (no GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Gold (GPRD: OFF)\n",
      "================================================================================\n",
      "  Total features: 6 (baseline)\n",
      "Clean data: 5339 rows, 6 features\n",
      "Train: 4271 | Test: 1068\n",
      "Sequences - Train: (4256, 15, 6) | Test: (1053, 15, 6)\n",
      "Train R²: -0.0026 | Test R²: -0.1992\n",
      "Test RMSE: 0.0055 | MAE: 0.0045\n",
      "Sharpe: 0.461 | Alpha: -0.188\n",
      "Cum Return: 16.05% | Max DD: -10.17%\n",
      "\n",
      "================================================================================\n",
      "ENHANCED RUN: Gold (with GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Gold (GPRD: ON)\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 21 (with GPRD)\n",
      "Clean data: 5335 rows, 21 features\n",
      "Train: 4268 | Test: 1067\n",
      "Sequences - Train: (4253, 15, 21) | Test: (1052, 15, 21)\n",
      "Train R²: -0.0006 | Test R²: -0.1726\n",
      "Test RMSE: 0.0055 | MAE: 0.0044\n",
      "Sharpe: 0.659 | Alpha: -0.002\n",
      "Cum Return: 21.50% | Max DD: -9.32%\n",
      "\n",
      "================================================================================\n",
      "BASELINE RUN: WTI (no GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: WTI (GPRD: OFF)\n",
      "================================================================================\n",
      "  Total features: 6 (baseline)\n",
      "Clean data: 5348 rows, 6 features\n",
      "Train: 4278 | Test: 1070\n",
      "Sequences - Train: (4263, 15, 6) | Test: (1055, 15, 6)\n",
      "Train R²: -0.0002 | Test R²: -0.0081\n",
      "Test RMSE: 0.0991 | MAE: 0.0187\n",
      "Sharpe: -0.665 | Alpha: -0.279\n",
      "Cum Return: -113.47% | Max DD: -127.81%\n",
      "\n",
      "================================================================================\n",
      "ENHANCED RUN: WTI (with GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: WTI (GPRD: ON)\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 21 (with GPRD)\n",
      "Clean data: 5344 rows, 21 features\n",
      "Train: 4275 | Test: 1069\n",
      "Sequences - Train: (4260, 15, 21) | Test: (1054, 15, 21)\n",
      "Train R²: 0.4877 | Test R²: -0.0172\n",
      "Test RMSE: 0.0996 | MAE: 0.0162\n",
      "Sharpe: 0.600 | Alpha: 0.985\n",
      "Cum Return: 234.83% | Max DD: -47.97%\n",
      "\n",
      "================================================================================\n",
      "BASELINE RUN: Wheat (no GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Wheat (GPRD: OFF)\n",
      "================================================================================\n",
      "  Total features: 6 (baseline)\n",
      "Clean data: 5364 rows, 6 features\n",
      "Train: 4291 | Test: 1073\n",
      "Sequences - Train: (4276, 15, 6) | Test: (1058, 15, 6)\n",
      "Train R²: -0.0013 | Test R²: -0.1207\n",
      "Test RMSE: 0.0071 | MAE: 0.0060\n",
      "Sharpe: 0.632 | Alpha: -0.001\n",
      "Cum Return: 38.88% | Max DD: -14.14%\n",
      "\n",
      "================================================================================\n",
      "ENHANCED RUN: Wheat (with GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Wheat (GPRD: ON)\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 21 (with GPRD)\n",
      "Clean data: 5360 rows, 21 features\n",
      "Train: 4288 | Test: 1072\n",
      "Sequences - Train: (4273, 15, 21) | Test: (1057, 15, 21)\n",
      "Train R²: -0.0006 | Test R²: -0.1105\n",
      "Test RMSE: 0.0071 | MAE: 0.0060\n",
      "Sharpe: 0.646 | Alpha: -0.001\n",
      "Cum Return: 39.98% | Max DD: -14.14%\n",
      "\n",
      "================================================================================\n",
      "BASELINE RUN: NaturalGas (no GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: NaturalGas (GPRD: OFF)\n",
      "================================================================================\n",
      "  Total features: 6 (baseline)\n",
      "Clean data: 3691 rows, 6 features\n",
      "Train: 2952 | Test: 739\n",
      "Sequences - Train: (2937, 15, 6) | Test: (724, 15, 6)\n",
      "Train R²: -0.0003 | Test R²: -0.0558\n",
      "Test RMSE: 0.0151 | MAE: 0.0114\n",
      "Sharpe: -0.321 | Alpha: -0.110\n",
      "Cum Return: -26.64% | Max DD: -44.86%\n",
      "\n",
      "================================================================================\n",
      "ENHANCED RUN: NaturalGas (with GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: NaturalGas (GPRD: ON)\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 21 (with GPRD)\n",
      "Clean data: 3687 rows, 21 features\n",
      "Train: 2949 | Test: 738\n",
      "Sequences - Train: (2934, 15, 21) | Test: (723, 15, 21)\n",
      "Train R²: 0.3751 | Test R²: 0.4817\n",
      "Test RMSE: 0.0106 | MAE: 0.0080\n",
      "Sharpe: 0.197 | Alpha: 0.421\n",
      "Cum Return: 4.88% | Max DD: -44.65%\n",
      "\n",
      "================================================================================\n",
      "BASELINE RUN: Copper (no GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Copper (GPRD: OFF)\n",
      "================================================================================\n",
      "  Total features: 6 (baseline)\n",
      "Clean data: 5343 rows, 6 features\n",
      "Train: 4274 | Test: 1069\n",
      "Sequences - Train: (4259, 15, 6) | Test: (1054, 15, 6)\n",
      "Train R²: -0.0024 | Test R²: -0.3344\n",
      "Test RMSE: 0.0068 | MAE: 0.0058\n",
      "Sharpe: 0.465 | Alpha: -0.014\n",
      "Cum Return: 20.39% | Max DD: -19.08%\n",
      "\n",
      "================================================================================\n",
      "ENHANCED RUN: Copper (with GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Copper (GPRD: ON)\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 21 (with GPRD)\n",
      "Clean data: 5339 rows, 21 features\n",
      "Train: 4271 | Test: 1068\n",
      "Sequences - Train: (4256, 15, 21) | Test: (1053, 15, 21)\n",
      "Train R²: 0.4903 | Test R²: 0.2110\n",
      "Test RMSE: 0.0053 | MAE: 0.0040\n",
      "Sharpe: -0.039 | Alpha: -0.523\n",
      "Cum Return: -5.71% | Max DD: -29.48%\n",
      "\n",
      "================================================================================\n",
      "BASELINE RUN: Lithium (no GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Lithium (GPRD: OFF)\n",
      "================================================================================\n",
      "  Total features: 6 (baseline)\n",
      "Clean data: 2868 rows, 6 features\n",
      "Train: 2294 | Test: 574\n",
      "Sequences - Train: (2279, 15, 6) | Test: (559, 15, 6)\n",
      "Train R²: -0.0001 | Test R²: -0.4888\n",
      "Test RMSE: 0.0160 | MAE: 0.0109\n",
      "Sharpe: 1.626 | Alpha: -0.001\n",
      "Cum Return: 96.52% | Max DD: -25.87%\n",
      "\n",
      "================================================================================\n",
      "ENHANCED RUN: Lithium (with GPRD)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing: Lithium (GPRD: ON)\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 21 (with GPRD)\n",
      "Clean data: 2864 rows, 21 features\n",
      "Train: 2291 | Test: 573\n",
      "Sequences - Train: (2276, 15, 21) | Test: (558, 15, 21)\n",
      "Train R²: -0.0002 | Test R²: -0.4858\n",
      "Test RMSE: 0.0160 | MAE: 0.0109\n",
      "Sharpe: 1.628 | Alpha: -0.001\n",
      "Cum Return: 96.60% | Max DD: -25.87%\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: GPRD Impact Analysis\n",
      "================================================================================\n",
      "     commodity  use_gprd  n_features   test_r2    sharpe     alpha  \\\n",
      "0         Gold     False           6 -0.199206  0.460721 -0.187543   \n",
      "1         Gold      True          21 -0.172557  0.658553 -0.001588   \n",
      "2          WTI     False           6 -0.008050 -0.664635 -0.279438   \n",
      "3          WTI      True          21 -0.017220  0.600364  0.984970   \n",
      "4        Wheat     False           6 -0.120702  0.632265 -0.000889   \n",
      "5        Wheat      True          21 -0.110504  0.646279 -0.000810   \n",
      "6   NaturalGas     False           6 -0.055770 -0.320595 -0.110027   \n",
      "7   NaturalGas      True          21  0.481651  0.197323  0.421126   \n",
      "8       Copper     False           6 -0.334430  0.464943 -0.014397   \n",
      "9       Copper      True          21  0.211045 -0.038561 -0.523377   \n",
      "10     Lithium     False           6 -0.488837  1.625660 -0.001146   \n",
      "11     Lithium      True          21 -0.485805  1.628105 -0.001115   \n",
      "\n",
      "    cumulative_return  \n",
      "0           16.051013  \n",
      "1           21.501254  \n",
      "2         -113.471381  \n",
      "3          234.828687  \n",
      "4           38.882110  \n",
      "5           39.975183  \n",
      "6          -26.636105  \n",
      "7            4.884703  \n",
      "8           20.389160  \n",
      "9           -5.711951  \n",
      "10          96.518363  \n",
      "11          96.599426  \n",
      "\n",
      "================================================================================\n",
      "Average Performance: WITH vs WITHOUT GPRD\n",
      "================================================================================\n",
      "           test_r2    sharpe     alpha  cumulative_return\n",
      "use_gprd                                                 \n",
      "False    -0.201166  0.366393 -0.098907           5.288860\n",
      "True     -0.015565  0.615344  0.146534          65.346217\n",
      "\n",
      "================================================================================\n",
      "GPRD Improvement by Commodity\n",
      "================================================================================\n",
      "Gold        : Sharpe 0.461 → 0.659 (↑ 0.198)\n",
      "WTI         : Sharpe -0.665 → 0.600 (↑ 1.265)\n",
      "Wheat       : Sharpe 0.632 → 0.646 (↑ 0.014)\n",
      "NaturalGas  : Sharpe -0.321 → 0.197 (↑ 0.518)\n",
      "Copper      : Sharpe 0.465 → -0.039 (↓ 0.504)\n",
      "Lithium     : Sharpe 1.626 → 1.628 (↑ 0.002)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T14:44:56.730294Z",
     "start_time": "2025-11-26T14:25:37.058224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE ABLATION ANALYSIS - All Commodities\n",
    "# Run this to analyze Return lag impact across all commodities with SHAP\n",
    "# =============================================================================\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import seaborn as sns\n",
    "import os\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Configuration\n",
    "# --------------------------------------------------------------\n",
    "ROOT = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "ENRICHED_DIR = os.path.join(DATA_DIR, \"enriched\")\n",
    "MODEL_RESULTS_DIR = os.path.join(DATA_DIR, 'model_results')\n",
    "os.makedirs(MODEL_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "commodities = [\"Gold\", \"WTI\", \"Wheat\", \"NaturalGas\", \"Copper\", \"Lithium\"]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Main function to run ablation analysis\n",
    "# --------------------------------------------------------------\n",
    "def run_ablation_analysis(commodity_name, df, use_gprd=True, include_return_lags=True, compute_shap=False):\n",
    "    \"\"\"\n",
    "    Run LSTM with optional Return lags and GPRD features\n",
    "    Returns results dict with metrics and optionally SHAP values\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing: {commodity_name} | GPRD: {'ON' if use_gprd else 'OFF'} | Return lags: {'YES' if include_return_lags else 'NO'}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    df_work = df.copy().sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Find and standardize Close column\n",
    "    close_col = None\n",
    "    for col in df_work.columns:\n",
    "        if 'Close' in col or 'close' in col:\n",
    "            close_col = col\n",
    "            break\n",
    "\n",
    "    if close_col is None:\n",
    "        print(f\"ERROR: No Close column found\")\n",
    "        return None\n",
    "\n",
    "    if close_col != 'Close':\n",
    "        df_work['Close'] = df_work[close_col]\n",
    "\n",
    "    # Calculate basic features\n",
    "    if 'Return' not in df_work.columns:\n",
    "        df_work['Return'] = df_work['Close'].pct_change()\n",
    "    if 'Vol_5' not in df_work.columns:\n",
    "        df_work['Vol_5'] = df_work['Return'].rolling(5).std()\n",
    "\n",
    "    # Base features to lag\n",
    "    base_features = ['Vol_5']\n",
    "    if include_return_lags:\n",
    "        base_features.append('Return')\n",
    "\n",
    "    # GPRD features (optional)\n",
    "    gprd_features = []\n",
    "    if use_gprd and 'GPRD' in df_work.columns:\n",
    "        df_work['GPRD'] = df_work['GPRD'].ffill().fillna(0)\n",
    "        df_work['GPRD_ma5'] = df_work['GPRD'].rolling(5).mean()\n",
    "        df_work['GPRD_high_regime'] = (df_work['GPRD'] > df_work['GPRD'].rolling(60).quantile(0.75)).astype(int)\n",
    "        gprd_features = ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
    "        print(f\"  Added GPRD features: {gprd_features}\")\n",
    "\n",
    "    # Create lagged features\n",
    "    features_to_lag = base_features + gprd_features\n",
    "    max_lag = 3\n",
    "    for feat in features_to_lag:\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            df_work[f'{feat}_lag{lag}'] = df_work[feat].shift(lag)\n",
    "\n",
    "    feature_cols = [f'{feat}_lag{lag}' for feat in features_to_lag for lag in range(1, max_lag + 1)]\n",
    "    print(f\"  Total features: {len(feature_cols)}\")\n",
    "\n",
    "    # Clean data\n",
    "    required_cols = ['Date', 'Vol_5', 'Return'] + feature_cols\n",
    "    df_clean = df_work[required_cols].dropna().reset_index(drop=True)\n",
    "    print(f\"  Clean data: {len(df_clean)} rows\")\n",
    "\n",
    "    if len(df_clean) < 100:\n",
    "        print(\"  ERROR: Insufficient data\")\n",
    "        return None\n",
    "\n",
    "    # Train/test split\n",
    "    split_idx = int(len(df_clean) * 0.8)\n",
    "    train_df = df_clean.iloc[:split_idx].copy()\n",
    "    test_df = df_clean.iloc[split_idx:].copy()\n",
    "    print(f\"  Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "    if len(train_df) < 50 or len(test_df) < 20:\n",
    "        print(\"  ERROR: Insufficient train/test data\")\n",
    "        return None\n",
    "\n",
    "    # Scale features\n",
    "    scaler = RobustScaler()\n",
    "    X_train = scaler.fit_transform(train_df[feature_cols])\n",
    "    X_test = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "    # Rebuild as DataFrames\n",
    "    train_scaled = pd.DataFrame(X_train, columns=feature_cols)\n",
    "    test_scaled = pd.DataFrame(X_test, columns=feature_cols)\n",
    "    train_scaled['Vol_5'] = train_df['Vol_5'].values\n",
    "    test_scaled['Vol_5'] = test_df['Vol_5'].values\n",
    "    train_scaled['Return'] = train_df['Return'].values\n",
    "    test_scaled['Return'] = test_df['Return'].values\n",
    "\n",
    "    # Create sequences\n",
    "    seq_length = 15\n",
    "    X_train_seq, y_train_seq = create_sequences(train_scaled, feature_cols, 'Vol_5', seq_length)\n",
    "    X_test_seq, y_test_seq = create_sequences(test_scaled, feature_cols, 'Vol_5', seq_length)\n",
    "    print(f\"  Sequences - Train: {X_train_seq.shape} | Test: {X_test_seq.shape}\")\n",
    "\n",
    "    if len(X_train_seq) < 20 or len(X_test_seq) < 5:\n",
    "        print(\"  ERROR: Insufficient sequences\")\n",
    "        return None\n",
    "\n",
    "    # Build model\n",
    "    model = Sequential([\n",
    "        Input(shape=(seq_length, len(feature_cols))),\n",
    "        LSTM(32, return_sequences=True, kernel_regularizer=l1_l2(l1=0.0001, l2=0.001)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(16, kernel_regularizer=l1_l2(l1=0.0001, l2=0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber', metrics=['mae'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=0)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, verbose=0)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train_seq, verbose=0).squeeze()\n",
    "    y_pred_test = model.predict(X_test_seq, verbose=0).squeeze()\n",
    "\n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train_seq, y_pred_train)\n",
    "    test_r2 = r2_score(y_test_seq, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_seq, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test_seq, y_pred_test)\n",
    "\n",
    "    print(f\"  Train R²: {train_r2:.4f} | Test R²: {test_r2:.4f}\")\n",
    "    print(f\"  Test RMSE: {test_rmse:.4f} | MAE: {test_mae:.4f}\")\n",
    "\n",
    "    # Backtest\n",
    "    test_returns = test_scaled['Return'].iloc[seq_length:].values\n",
    "    backtest_results = backtest_volatility_strategy(y_pred_test, y_test_seq, test_returns)\n",
    "\n",
    "    print(f\"  Sharpe: {backtest_results['sharpe']:.3f} | Alpha: {backtest_results['alpha']:.3f}\")\n",
    "    print(f\"  Cum Return: {backtest_results['cumulative_return']:.2f}% | Max DD: {backtest_results['max_drawdown']:.2f}%\")\n",
    "\n",
    "    results = {\n",
    "        'commodity': commodity_name,\n",
    "        'use_gprd': use_gprd,\n",
    "        'include_return_lags': include_return_lags,\n",
    "        'n_features': len(feature_cols),\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        **backtest_results\n",
    "    }\n",
    "\n",
    "    # Feature importance analysis (if requested)\n",
    "    importance_df = None\n",
    "    if compute_shap and len(X_test_seq) >= 50:\n",
    "        try:\n",
    "            print(\"  Computing feature importance (using gradient-based method)...\")\n",
    "\n",
    "            # Use a simpler, more reliable method: average absolute gradients\n",
    "            import tensorflow as tf\n",
    "\n",
    "            # Get gradients for a sample of test data\n",
    "            sample_size = min(200, len(X_test_seq))\n",
    "            sample_indices = np.random.choice(len(X_test_seq), sample_size, replace=False)\n",
    "            X_sample = X_test_seq[sample_indices]\n",
    "\n",
    "            # Compute gradients\n",
    "            gradients_list = []\n",
    "            for i in range(sample_size):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    x_tensor = tf.constant(X_sample[i:i+1], dtype=tf.float32)\n",
    "                    tape.watch(x_tensor)\n",
    "                    predictions = model(x_tensor, training=False)\n",
    "\n",
    "                grads = tape.gradient(predictions, x_tensor)\n",
    "                gradients_list.append(np.abs(grads.numpy()))\n",
    "\n",
    "            # Average across samples and time steps\n",
    "            avg_gradients = np.mean(gradients_list, axis=(0, 1))  # Shape: (n_features,)\n",
    "\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance': avg_gradients\n",
    "            }).sort_values('importance', ascending=False)\n",
    "\n",
    "            results['top_feature'] = importance_df.iloc[0]['feature']\n",
    "            results['top_importance'] = importance_df.iloc[0]['importance']\n",
    "\n",
    "            print(f\"  Top feature: {results['top_feature']} (importance: {results['top_importance']:.6f})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Feature importance computation failed: {e}\")\n",
    "\n",
    "    return results, model, X_test_seq, y_pred_test, y_test_seq, feature_cols, importance_df\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Run comprehensive experiments\n",
    "# --------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading enriched data...\")\n",
    "    merged_data = {}\n",
    "\n",
    "    for name in commodities:\n",
    "        fname = f\"{name.lower()}_enriched.csv\"\n",
    "        path = os.path.join(ENRICHED_DIR, fname)\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            merged_data[name] = df\n",
    "            has_gprd = 'GPRD' in df.columns\n",
    "            print(f\"  Loaded {name}: {len(df)} rows | GPRD: {'✓' if has_gprd else '✗'} | Cols: {len(df.columns)}\")\n",
    "        else:\n",
    "            print(f\"  Missing: {name}\")\n",
    "\n",
    "    all_results = []\n",
    "    importance_results = {}\n",
    "\n",
    "    for commodity in merged_data.keys():\n",
    "        # Run 4 configurations per commodity:\n",
    "        # 1. Baseline (no GPRD, with Return lags)\n",
    "        # 2. No Return lags (no GPRD, without Return lags)\n",
    "        # 3. With GPRD (with GPRD, with Return lags)\n",
    "        # 4. With GPRD, no Return lags (with GPRD, without Return lags)\n",
    "\n",
    "        # Configuration 1: Baseline (no GPRD, with Return lags)\n",
    "        result = run_ablation_analysis(commodity, merged_data[commodity],\n",
    "                                      use_gprd=False, include_return_lags=True,\n",
    "                                      compute_shap=False)\n",
    "        if result and result[0]:\n",
    "            all_results.append(result[0])\n",
    "\n",
    "        # Configuration 2: No Return lags (no GPRD, without Return lags)\n",
    "        result = run_ablation_analysis(commodity, merged_data[commodity],\n",
    "                                      use_gprd=False, include_return_lags=False,\n",
    "                                      compute_shap=False)\n",
    "        if result and result[0]:\n",
    "            all_results.append(result[0])\n",
    "\n",
    "        # Configuration 3: With GPRD (if available)\n",
    "        if 'GPRD' in merged_data[commodity].columns:\n",
    "            result = run_ablation_analysis(commodity, merged_data[commodity],\n",
    "                                          use_gprd=True, include_return_lags=True,\n",
    "                                          compute_shap=True)  # Compute importance for best model\n",
    "            if result and result[0]:\n",
    "                all_results.append(result[0])\n",
    "                # Store importance results for later display\n",
    "                if result[6] is not None:  # importance_df\n",
    "                    importance_results[commodity] = {\n",
    "                        'importance_df': result[6],\n",
    "                        'feature_cols': result[5]\n",
    "                    }\n",
    "\n",
    "            # Configuration 4: With GPRD, no Return lags\n",
    "            result = run_ablation_analysis(commodity, merged_data[commodity],\n",
    "                                          use_gprd=True, include_return_lags=False,\n",
    "                                          compute_shap=False)\n",
    "            if result and result[0]:\n",
    "                all_results.append(result[0])\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # Save and display results\n",
    "    # --------------------------------------------------------------\n",
    "    if len(all_results) > 0:\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        results_df.to_csv(os.path.join(MODEL_RESULTS_DIR, 'lstm_ablation_analysis.csv'), index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ABLATION ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(results_df[['commodity', 'use_gprd', 'include_return_lags', 'n_features',\n",
    "                         'test_r2', 'sharpe', 'alpha', 'cumulative_return']])\n",
    "\n",
    "        # Compare Return lag impact (no GPRD)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RETURN LAG IMPACT (Baseline - No GPRD)\")\n",
    "        print(\"=\"*80)\n",
    "        baseline = results_df[(results_df['use_gprd'] == False)]\n",
    "        for commodity in baseline['commodity'].unique():\n",
    "            subset = baseline[baseline['commodity'] == commodity]\n",
    "            if len(subset) == 2:\n",
    "                with_ret = subset[subset['include_return_lags'] == True].iloc[0]\n",
    "                without_ret = subset[subset['include_return_lags'] == False].iloc[0]\n",
    "                sharpe_diff = with_ret['sharpe'] - without_ret['sharpe']\n",
    "                print(f\"{commodity:12s}: Sharpe {without_ret['sharpe']:6.3f} → {with_ret['sharpe']:6.3f} \"\n",
    "                      f\"({'↑' if sharpe_diff > 0 else '↓'} {abs(sharpe_diff):.3f})\")\n",
    "\n",
    "        # Compare GPRD impact (with Return lags)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GPRD IMPACT (With Return lags)\")\n",
    "        print(\"=\"*80)\n",
    "        with_return = results_df[(results_df['include_return_lags'] == True)]\n",
    "        for commodity in with_return['commodity'].unique():\n",
    "            subset = with_return[with_return['commodity'] == commodity]\n",
    "            if len(subset) == 2:\n",
    "                baseline = subset[subset['use_gprd'] == False].iloc[0]\n",
    "                gprd = subset[subset['use_gprd'] == True].iloc[0]\n",
    "                sharpe_diff = gprd['sharpe'] - baseline['sharpe']\n",
    "                print(f\"{commodity:12s}: Sharpe {baseline['sharpe']:6.3f} → {gprd['sharpe']:6.3f} \"\n",
    "                      f\"({'↑' if sharpe_diff > 0 else '↓'} {abs(sharpe_diff):.3f})\")\n",
    "\n",
    "        # Display feature importance results\n",
    "        if importance_results:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"TOP FEATURES BY COMMODITY (Gradient-based Importance - GPRD Models)\")\n",
    "            print(\"=\"*80)\n",
    "            for commodity, data in importance_results.items():\n",
    "                print(f\"\\n{commodity}:\")\n",
    "                print(data['importance_df'].head(10).to_string(index=False))\n",
    "\n",
    "        # Summary statistics\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"AVERAGE PERFORMANCE BY CONFIGURATION\")\n",
    "        print(\"=\"*80)\n",
    "        summary = results_df.groupby(['use_gprd', 'include_return_lags'])[\n",
    "            ['test_r2', 'sharpe', 'alpha', 'cumulative_return']\n",
    "        ].mean()\n",
    "        print(summary)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo successful results to save!\")\n",
    "\n",
    "    print(\"\\n✓ Ablation analysis complete!\")"
   ],
   "id": "23a17da8b6d13fbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading enriched data...\n",
      "  Loaded Gold: 5342 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded WTI: 5351 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded Wheat: 5367 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded NaturalGas: 3694 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded Copper: 5346 rows | GPRD: ✓ | Cols: 17\n",
      "  Loaded Lithium: 2871 rows | GPRD: ✓ | Cols: 17\n",
      "\n",
      "================================================================================\n",
      "Processing: Gold | GPRD: OFF | Return lags: YES\n",
      "================================================================================\n",
      "  Total features: 6\n",
      "  Clean data: 5339 rows\n",
      "  Train: 4271 | Test: 1068\n",
      "  Sequences - Train: (4256, 15, 6) | Test: (1053, 15, 6)\n",
      "  Train R²: -0.0054 | Test R²: -0.2215\n",
      "  Test RMSE: 0.0056 | MAE: 0.0045\n",
      "  Sharpe: 0.647 | Alpha: -0.002\n",
      "  Cum Return: 21.07% | Max DD: -9.32%\n",
      "\n",
      "================================================================================\n",
      "Processing: Gold | GPRD: OFF | Return lags: NO\n",
      "================================================================================\n",
      "  Total features: 3\n",
      "  Clean data: 5339 rows\n",
      "  Train: 4271 | Test: 1068\n",
      "  Sequences - Train: (4256, 15, 3) | Test: (1053, 15, 3)\n",
      "  Train R²: -0.0047 | Test R²: -0.2165\n",
      "  Test RMSE: 0.0056 | MAE: 0.0045\n",
      "  Sharpe: 0.647 | Alpha: -0.002\n",
      "  Cum Return: 21.07% | Max DD: -9.32%\n",
      "\n",
      "================================================================================\n",
      "Processing: Gold | GPRD: ON | Return lags: YES\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 15\n",
      "  Clean data: 5335 rows\n",
      "  Train: 4268 | Test: 1067\n",
      "  Sequences - Train: (4253, 15, 15) | Test: (1052, 15, 15)\n",
      "  Train R²: -0.0043 | Test R²: -0.2122\n",
      "  Test RMSE: 0.0055 | MAE: 0.0045\n",
      "  Sharpe: 0.659 | Alpha: -0.002\n",
      "  Cum Return: 21.50% | Max DD: -9.32%\n",
      "  Computing feature importance (using gradient-based method)...\n",
      "  Feature importance computation failed: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "Processing: Gold | GPRD: ON | Return lags: NO\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 12\n",
      "  Clean data: 5335 rows\n",
      "  Train: 4268 | Test: 1067\n",
      "  Sequences - Train: (4253, 15, 12) | Test: (1052, 15, 12)\n",
      "  Train R²: -0.0021 | Test R²: -0.1929\n",
      "  Test RMSE: 0.0055 | MAE: 0.0044\n",
      "  Sharpe: 0.659 | Alpha: -0.002\n",
      "  Cum Return: 21.50% | Max DD: -9.32%\n",
      "\n",
      "================================================================================\n",
      "Processing: WTI | GPRD: OFF | Return lags: YES\n",
      "================================================================================\n",
      "  Total features: 6\n",
      "  Clean data: 5348 rows\n",
      "  Train: 4278 | Test: 1070\n",
      "  Sequences - Train: (4263, 15, 6) | Test: (1055, 15, 6)\n",
      "  Train R²: -0.0002 | Test R²: -0.0081\n",
      "  Test RMSE: 0.0991 | MAE: 0.0187\n",
      "  Sharpe: -0.476 | Alpha: -0.091\n",
      "  Cum Return: -126.20% | Max DD: -137.04%\n",
      "\n",
      "================================================================================\n",
      "Processing: WTI | GPRD: OFF | Return lags: NO\n",
      "================================================================================\n",
      "  Total features: 3\n",
      "  Clean data: 5348 rows\n",
      "  Train: 4278 | Test: 1070\n",
      "  Sequences - Train: (4263, 15, 3) | Test: (1055, 15, 3)\n",
      "  Train R²: -0.0003 | Test R²: -0.0080\n",
      "  Test RMSE: 0.0991 | MAE: 0.0187\n",
      "  Sharpe: 0.507 | Alpha: 0.892\n",
      "  Cum Return: 147.25% | Max DD: -56.41%\n",
      "\n",
      "================================================================================\n",
      "Processing: WTI | GPRD: ON | Return lags: YES\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 15\n",
      "  Clean data: 5344 rows\n",
      "  Train: 4275 | Test: 1069\n",
      "  Sequences - Train: (4260, 15, 15) | Test: (1054, 15, 15)\n",
      "  Train R²: -0.0000 | Test R²: -0.0084\n",
      "  Test RMSE: 0.0992 | MAE: 0.0186\n",
      "  Sharpe: -0.342 | Alpha: 0.043\n",
      "  Cum Return: -138.25% | Max DD: -133.08%\n",
      "  Computing feature importance (using gradient-based method)...\n",
      "  Feature importance computation failed: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "Processing: WTI | GPRD: ON | Return lags: NO\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 12\n",
      "  Clean data: 5344 rows\n",
      "  Train: 4275 | Test: 1069\n",
      "  Sequences - Train: (4260, 15, 12) | Test: (1054, 15, 12)\n",
      "  Train R²: -0.0001 | Test R²: -0.0086\n",
      "  Test RMSE: 0.0992 | MAE: 0.0186\n",
      "  Sharpe: -0.259 | Alpha: 0.126\n",
      "  Cum Return: -151.13% | Max DD: -144.19%\n",
      "\n",
      "================================================================================\n",
      "Processing: Wheat | GPRD: OFF | Return lags: YES\n",
      "================================================================================\n",
      "  Total features: 6\n",
      "  Clean data: 5364 rows\n",
      "  Train: 4291 | Test: 1073\n",
      "  Sequences - Train: (4276, 15, 6) | Test: (1058, 15, 6)\n",
      "  Train R²: -0.0028 | Test R²: -0.1372\n",
      "  Test RMSE: 0.0072 | MAE: 0.0061\n",
      "  Sharpe: 0.632 | Alpha: -0.001\n",
      "  Cum Return: 38.88% | Max DD: -14.14%\n",
      "\n",
      "================================================================================\n",
      "Processing: Wheat | GPRD: OFF | Return lags: NO\n",
      "================================================================================\n",
      "  Total features: 3\n",
      "  Clean data: 5364 rows\n",
      "  Train: 4291 | Test: 1073\n",
      "  Sequences - Train: (4276, 15, 3) | Test: (1058, 15, 3)\n",
      "  Train R²: -0.0019 | Test R²: -0.1276\n",
      "  Test RMSE: 0.0072 | MAE: 0.0060\n",
      "  Sharpe: 0.632 | Alpha: -0.001\n",
      "  Cum Return: 38.88% | Max DD: -14.14%\n",
      "\n",
      "================================================================================\n",
      "Processing: Wheat | GPRD: ON | Return lags: YES\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 15\n",
      "  Clean data: 5360 rows\n",
      "  Train: 4288 | Test: 1072\n",
      "  Sequences - Train: (4273, 15, 15) | Test: (1057, 15, 15)\n",
      "  Train R²: -0.0014 | Test R²: -0.1220\n",
      "  Test RMSE: 0.0071 | MAE: 0.0060\n",
      "  Sharpe: 0.646 | Alpha: -0.001\n",
      "  Cum Return: 39.98% | Max DD: -14.14%\n",
      "  Computing feature importance (using gradient-based method)...\n",
      "  Feature importance computation failed: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "Processing: Wheat | GPRD: ON | Return lags: NO\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 12\n",
      "  Clean data: 5360 rows\n",
      "  Train: 4288 | Test: 1072\n",
      "  Sequences - Train: (4273, 15, 12) | Test: (1057, 15, 12)\n",
      "  Train R²: -0.0010 | Test R²: -0.1160\n",
      "  Test RMSE: 0.0071 | MAE: 0.0060\n",
      "  Sharpe: 0.646 | Alpha: -0.001\n",
      "  Cum Return: 39.98% | Max DD: -14.14%\n",
      "\n",
      "================================================================================\n",
      "Processing: NaturalGas | GPRD: OFF | Return lags: YES\n",
      "================================================================================\n",
      "  Total features: 6\n",
      "  Clean data: 3691 rows\n",
      "  Train: 2952 | Test: 739\n",
      "  Sequences - Train: (2937, 15, 6) | Test: (724, 15, 6)\n",
      "  Train R²: -0.0009 | Test R²: -0.0389\n",
      "  Test RMSE: 0.0150 | MAE: 0.0114\n",
      "  Sharpe: -0.211 | Alpha: -0.001\n",
      "  Cum Return: -20.80% | Max DD: -39.24%\n",
      "\n",
      "================================================================================\n",
      "Processing: NaturalGas | GPRD: OFF | Return lags: NO\n",
      "================================================================================\n",
      "  Total features: 3\n",
      "  Clean data: 3691 rows\n",
      "  Train: 2952 | Test: 739\n",
      "  Sequences - Train: (2937, 15, 3) | Test: (724, 15, 3)\n",
      "  Train R²: -0.0004 | Test R²: -0.0425\n",
      "  Test RMSE: 0.0151 | MAE: 0.0114\n",
      "  Sharpe: -0.211 | Alpha: -0.001\n",
      "  Cum Return: -20.80% | Max DD: -39.24%\n",
      "\n",
      "================================================================================\n",
      "Processing: NaturalGas | GPRD: ON | Return lags: YES\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 15\n",
      "  Clean data: 3687 rows\n",
      "  Train: 2949 | Test: 738\n",
      "  Sequences - Train: (2934, 15, 15) | Test: (723, 15, 15)\n",
      "  Train R²: -0.0014 | Test R²: -0.0363\n",
      "  Test RMSE: 0.0150 | MAE: 0.0115\n",
      "  Sharpe: -0.225 | Alpha: -0.001\n",
      "  Cum Return: -21.51% | Max DD: -39.24%\n",
      "  Computing feature importance (using gradient-based method)...\n",
      "  Feature importance computation failed: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "Processing: NaturalGas | GPRD: ON | Return lags: NO\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 12\n",
      "  Clean data: 3687 rows\n",
      "  Train: 2949 | Test: 738\n",
      "  Sequences - Train: (2934, 15, 12) | Test: (723, 15, 12)\n",
      "  Train R²: -0.0008 | Test R²: -0.0396\n",
      "  Test RMSE: 0.0150 | MAE: 0.0114\n",
      "  Sharpe: -0.234 | Alpha: -0.010\n",
      "  Cum Return: -22.04% | Max DD: -40.30%\n",
      "\n",
      "================================================================================\n",
      "Processing: Copper | GPRD: OFF | Return lags: YES\n",
      "================================================================================\n",
      "  Total features: 6\n",
      "  Clean data: 5343 rows\n",
      "  Train: 4274 | Test: 1069\n",
      "  Sequences - Train: (4259, 15, 6) | Test: (1054, 15, 6)\n",
      "  Train R²: -0.0067 | Test R²: -0.3989\n",
      "  Test RMSE: 0.0070 | MAE: 0.0060\n",
      "  Sharpe: 0.478 | Alpha: -0.001\n",
      "  Cum Return: 21.11% | Max DD: -19.08%\n",
      "\n",
      "================================================================================\n",
      "Processing: Copper | GPRD: OFF | Return lags: NO\n",
      "================================================================================\n",
      "  Total features: 3\n",
      "  Clean data: 5343 rows\n",
      "  Train: 4274 | Test: 1069\n",
      "  Sequences - Train: (4259, 15, 3) | Test: (1054, 15, 3)\n",
      "  Train R²: -0.0007 | Test R²: -0.2934\n",
      "  Test RMSE: 0.0067 | MAE: 0.0057\n",
      "  Sharpe: 0.360 | Alpha: -0.119\n",
      "  Cum Return: 14.80% | Max DD: -18.64%\n",
      "\n",
      "================================================================================\n",
      "Processing: Copper | GPRD: ON | Return lags: YES\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 15\n",
      "  Clean data: 5339 rows\n",
      "  Train: 4271 | Test: 1068\n",
      "  Sequences - Train: (4256, 15, 15) | Test: (1053, 15, 15)\n",
      "  Train R²: -0.0052 | Test R²: -0.3787\n",
      "  Test RMSE: 0.0069 | MAE: 0.0059\n",
      "  Sharpe: 0.484 | Alpha: -0.001\n",
      "  Cum Return: 21.39% | Max DD: -19.08%\n",
      "  Computing feature importance (using gradient-based method)...\n",
      "  Feature importance computation failed: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "Processing: Copper | GPRD: ON | Return lags: NO\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 12\n",
      "  Clean data: 5339 rows\n",
      "  Train: 4271 | Test: 1068\n",
      "  Sequences - Train: (4256, 15, 12) | Test: (1053, 15, 12)\n",
      "  Train R²: -0.0072 | Test R²: -0.4037\n",
      "  Test RMSE: 0.0070 | MAE: 0.0060\n",
      "  Sharpe: 0.484 | Alpha: -0.001\n",
      "  Cum Return: 21.39% | Max DD: -19.08%\n",
      "\n",
      "================================================================================\n",
      "Processing: Lithium | GPRD: OFF | Return lags: YES\n",
      "================================================================================\n",
      "  Total features: 6\n",
      "  Clean data: 2868 rows\n",
      "  Train: 2294 | Test: 574\n",
      "  Sequences - Train: (2279, 15, 6) | Test: (559, 15, 6)\n",
      "  Train R²: -0.0000 | Test R²: -0.4949\n",
      "  Test RMSE: 0.0161 | MAE: 0.0109\n",
      "  Sharpe: 1.758 | Alpha: 0.132\n",
      "  Cum Return: 115.30% | Max DD: -25.87%\n",
      "\n",
      "================================================================================\n",
      "Processing: Lithium | GPRD: OFF | Return lags: NO\n",
      "================================================================================\n",
      "  Total features: 3\n",
      "  Clean data: 2868 rows\n",
      "  Train: 2294 | Test: 574\n",
      "  Sequences - Train: (2279, 15, 3) | Test: (559, 15, 3)\n",
      "  Train R²: -0.0003 | Test R²: -0.4829\n",
      "  Test RMSE: 0.0160 | MAE: 0.0109\n",
      "  Sharpe: 1.626 | Alpha: -0.001\n",
      "  Cum Return: 96.52% | Max DD: -25.87%\n",
      "\n",
      "================================================================================\n",
      "Processing: Lithium | GPRD: ON | Return lags: YES\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 15\n",
      "  Clean data: 2864 rows\n",
      "  Train: 2291 | Test: 573\n",
      "  Sequences - Train: (2276, 15, 15) | Test: (558, 15, 15)\n",
      "  Train R²: -0.0001 | Test R²: -0.4897\n",
      "  Test RMSE: 0.0160 | MAE: 0.0109\n",
      "  Sharpe: 1.628 | Alpha: -0.001\n",
      "  Cum Return: 96.60% | Max DD: -25.87%\n",
      "  Computing feature importance (using gradient-based method)...\n",
      "  Feature importance computation failed: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "Processing: Lithium | GPRD: ON | Return lags: NO\n",
      "================================================================================\n",
      "  Added GPRD features: ['GPRD', 'GPRD_ma5', 'GPRD_high_regime']\n",
      "  Total features: 12\n",
      "  Clean data: 2864 rows\n",
      "  Train: 2291 | Test: 573\n",
      "  Sequences - Train: (2276, 15, 12) | Test: (558, 15, 12)\n",
      "  Train R²: -0.0008 | Test R²: -0.4761\n",
      "  Test RMSE: 0.0160 | MAE: 0.0109\n",
      "  Sharpe: 1.628 | Alpha: -0.001\n",
      "  Cum Return: 96.60% | Max DD: -25.87%\n",
      "\n",
      "================================================================================\n",
      "ABLATION ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "     commodity  use_gprd  include_return_lags  n_features   test_r2    sharpe  \\\n",
      "0         Gold     False                 True           6 -0.221482  0.646617   \n",
      "1         Gold     False                False           3 -0.216505  0.646617   \n",
      "2         Gold      True                 True          15 -0.212246  0.658553   \n",
      "3         Gold      True                False          12 -0.192864  0.658553   \n",
      "4          WTI     False                 True           6 -0.008052 -0.475978   \n",
      "5          WTI     False                False           3 -0.007978  0.507061   \n",
      "6          WTI      True                 True          15 -0.008428 -0.341819   \n",
      "7          WTI      True                False          12 -0.008643 -0.259021   \n",
      "8        Wheat     False                 True           6 -0.137167  0.632265   \n",
      "9        Wheat     False                False           3 -0.127616  0.632265   \n",
      "10       Wheat      True                 True          15 -0.122026  0.646279   \n",
      "11       Wheat      True                False          12 -0.115961  0.646279   \n",
      "12  NaturalGas     False                 True           6 -0.038930 -0.211288   \n",
      "13  NaturalGas     False                False           3 -0.042542 -0.211288   \n",
      "14  NaturalGas      True                 True          15 -0.036332 -0.224518   \n",
      "15  NaturalGas      True                False          12 -0.039557 -0.234125   \n",
      "16      Copper     False                 True           6 -0.398850  0.478220   \n",
      "17      Copper     False                False           3 -0.293413  0.359944   \n",
      "18      Copper      True                 True          15 -0.378749  0.483703   \n",
      "19      Copper      True                False          12 -0.403711  0.483703   \n",
      "20     Lithium     False                 True           6 -0.494880  1.758407   \n",
      "21     Lithium     False                False           3 -0.482941  1.625660   \n",
      "22     Lithium      True                 True          15 -0.489735  1.628104   \n",
      "23     Lithium      True                False          12 -0.476076  1.628104   \n",
      "\n",
      "       alpha  cumulative_return  \n",
      "0  -0.001648          21.067529  \n",
      "1  -0.001648          21.067529  \n",
      "2  -0.001588          21.501254  \n",
      "3  -0.001588          21.501254  \n",
      "4  -0.090781        -126.201730  \n",
      "5   0.892258         147.247870  \n",
      "6   0.042787        -138.254158  \n",
      "7   0.125585        -151.130063  \n",
      "8  -0.000889          38.882110  \n",
      "9  -0.000889          38.882110  \n",
      "10 -0.000810          39.975183  \n",
      "11 -0.000810          39.975183  \n",
      "12 -0.000720         -20.798162  \n",
      "13 -0.000720         -20.798162  \n",
      "14 -0.000715         -21.514138  \n",
      "15 -0.010322         -22.035494  \n",
      "16 -0.001121          21.106298  \n",
      "17 -0.119397          14.802813  \n",
      "18 -0.001113          21.392123  \n",
      "19 -0.001113          21.392123  \n",
      "20  0.131601         115.303023  \n",
      "21 -0.001146          96.518353  \n",
      "22 -0.001115          96.599400  \n",
      "23 -0.001115          96.599400  \n",
      "\n",
      "================================================================================\n",
      "RETURN LAG IMPACT (Baseline - No GPRD)\n",
      "================================================================================\n",
      "Gold        : Sharpe  0.647 →  0.647 (↓ 0.000)\n",
      "WTI         : Sharpe  0.507 → -0.476 (↓ 0.983)\n",
      "Wheat       : Sharpe  0.632 →  0.632 (↓ 0.000)\n",
      "NaturalGas  : Sharpe -0.211 → -0.211 (↓ 0.000)\n",
      "Copper      : Sharpe  0.360 →  0.478 (↑ 0.118)\n",
      "Lithium     : Sharpe  1.626 →  1.758 (↑ 0.133)\n",
      "\n",
      "================================================================================\n",
      "GPRD IMPACT (With Return lags)\n",
      "================================================================================\n",
      "Gold        : Sharpe  0.647 →  0.659 (↑ 0.012)\n",
      "WTI         : Sharpe -0.476 → -0.342 (↑ 0.134)\n",
      "Wheat       : Sharpe  0.632 →  0.646 (↑ 0.014)\n",
      "NaturalGas  : Sharpe -0.211 → -0.225 (↓ 0.013)\n",
      "Copper      : Sharpe  0.478 →  0.484 (↑ 0.005)\n",
      "Lithium     : Sharpe  1.758 →  1.628 (↓ 0.130)\n",
      "\n",
      "================================================================================\n",
      "AVERAGE PERFORMANCE BY CONFIGURATION\n",
      "================================================================================\n",
      "                               test_r2    sharpe     alpha  cumulative_return\n",
      "use_gprd include_return_lags                                                 \n",
      "False    False               -0.195166  0.593376  0.128076          49.620085\n",
      "         True                -0.216560  0.471374  0.006074           8.226511\n",
      "True     False               -0.206135  0.487249  0.018439           1.050400\n",
      "         True                -0.207920  0.475050  0.006241           3.283277\n",
      "\n",
      "✓ Ablation analysis complete!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f32b17d2e0415c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 01_data_collection\n",
    "Fetch commodity prices (gold, oil, wheat) and load Kaggle datasets (geopolitical risk, global news).\n"
   ],
   "id": "8fbf7ae9f1fc341e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# If you don't have yfinance or kaggle installed, uncomment and run these:\n",
    " pip install yfinance kaggle\n"
   ],
   "id": "b80b1fe2130fdcf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# paths\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # if notebook lives in notebooks/\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# choose date range\n",
    "START = \"2000-01-01\"\n",
    "END = None  # None -> yfinance takes up to today\n"
   ],
   "id": "1d979d0e139e450a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tickers = {\n",
    "    \"Gold\": \"GC=F\",      # Gold futures\n",
    "    \"WTI\":  \"CL=F\",      # WTI crude oil future\n",
    "    \"Wheat\": \"ZW=F\"      # Wheat futures\n",
    "}\n",
    "\n",
    "def fetch_save(ticker_symbol, shortname):\n",
    "    print(f\"Downloading {shortname} ({ticker_symbol}) ...\")\n",
    "    df = yf.download(ticker_symbol, start=START, end=END, progress=False, auto_adjust=True)\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "    df['Vol_5'] = df['Return'].rolling(window=5).std()\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Warning: empty dataframe for\", ticker_symbol)\n",
    "    else:\n",
    "        df.reset_index(inplace=True)                 # Date as column\n",
    "        df.to_csv(os.path.join(DATA_DIR, f\"{shortname}.csv\"), index=False)\n",
    "    return df\n",
    "\n",
    "# fetch\n",
    "df_gold = fetch_save(tickers[\"Gold\"], \"gold_futures\")\n",
    "df_wti  = fetch_save(tickers[\"WTI\"], \"wti_crude\")\n",
    "df_wheat = fetch_save(tickers[\"Wheat\"], \"wheat_futures\")\n",
    "\n"
   ],
   "id": "5667f6f56214e1c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for name, df in [(\"Gold\", df_gold), (\"WTI\", df_wti), (\"Wheat\", df_wheat)]:\n",
    "    print(name, \"rows:\", 0 if df is None else len(df))\n",
    "    display(df.head())\n"
   ],
   "id": "47b963fe278c02d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# run in terminal (not in notebook) from repo root\n",
    "# pip install kaggle\n",
    "# mkdir -p ~/.kaggle && cp /path/to/kaggle.json ~/.kaggle/kaggle.json && chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Cell 6: Download all required Kaggle datasets\n",
    "\n",
    "import os\n",
    "\n",
    "# Make sure we have a \"data\" directory\n",
    "os.makedirs(\"../../data/data\", exist_ok=True)\n",
    "\n",
    "# 1. Gold & Silver Price vs Geopolitical Risk Index\n",
    "!kaggle datasets download -d shreyanshdangi/gold-silver-price-vs-geopolitical-risk-19852025 -p data --unzip\n",
    "\n",
    "# 2. Global News Dataset\n",
    "!kaggle datasets download -d everydaycodings/global-news-dataset -p data --unzip\n",
    "\n",
    "# 3. Gold Price Prediction (LSTM reference dataset)\n",
    "!kaggle kernels pull farzadnekouei/gold-price-prediction-lstm-96-accuracy -p data/lstm_reference\n",
    "\n"
   ],
   "id": "d790a38b671f830f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# list files so you can adapt filenames\n",
    "for f in sorted(os.listdir(DATA_DIR)):\n",
    "    print(f)\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# Example load (replace filenames with actual ones you see)\n",
    "gpr = pd.read_csv(os.path.join(DATA_DIR, \"Gold-Silver-GeopoliticalRisk_HistoricalData.csv\"))\n",
    "global_news = pd.read_csv(os.path.join(DATA_DIR, 'data.csv'))\n",
    "\n",
    "# Simple placeholder if you haven't downloaded: create an empty dataframe\n",
    "gpr = None\n",
    "global_news = None\n"
   ],
   "id": "3cdbad6bd8423e89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_basic_features(df):\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    df.set_index('Date', inplace=False)\n",
    "    price_col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
    "    df[price_col] = df[price_col].astype(float)\n",
    "    df['Return'] = df[price_col].pct_change()\n",
    "    df['MA_5'] = df[price_col].rolling(window=5).mean()\n",
    "    df['Vol_5'] = df['Return'].rolling(window=5).std()\n",
    "    return df\n",
    "\n",
    "gold_feat = add_basic_features(df_gold) if not df_gold.empty else pd.DataFrame()\n",
    "wti_feat  = add_basic_features(df_wti) if not df_wti.empty else pd.DataFrame()\n",
    "wheat_feat= add_basic_features(df_wheat) if not df_wheat.empty else pd.DataFrame()\n",
    "\n",
    "# Save processed\n",
    "gold_feat.to_csv(os.path.join(DATA_DIR, \"gold_processed.csv\"), index=False)\n",
    "wti_feat.to_csv(os.path.join(DATA_DIR, \"wti_processed.csv\"), index=False)\n",
    "wheat_feat.to_csv(os.path.join(DATA_DIR, \"wheat_processed.csv\"), index=False)\n",
    "\n",
    "print(\"Saved processed files to\", DATA_DIR)\n",
    "print(gpr.head())\n"
   ],
   "id": "d684bd9c892b722c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example: if you have a geopolitcal risk csv with 'Date' and 'GPR' columns\n",
    "# --- Prepare GPR data ---\n",
    "gpr['DATE'] = pd.to_datetime(gpr['DATE'])\n",
    "gpr_daily = gpr.set_index('DATE').resample('D').ffill().reset_index()\n",
    "\n",
    "# --- Prepare gold_feat ---\n",
    "# Only reset index if 'Date' is still the index (to avoid duplicates)\n",
    "if gold_feat.index.name == 'Date':\n",
    "    gold_feat = gold_feat.reset_index()\n",
    "\n",
    "print(\"Gold feature columns:\", gold_feat.columns)\n",
    "print(\"GPR columns:\", gpr_daily.columns)\n",
    "\n",
    "\n",
    "# --- Merge on Date ---\n",
    "merged_gold = pd.merge(\n",
    "    gold_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"Merged dataset preview:\")\n",
    "print(merged_gold.head())"
   ],
   "id": "940c5de47b6be780"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Prepare GPR data ---\n",
    "gpr['DATE'] = pd.to_datetime(gpr['DATE'])\n",
    "gpr_daily = gpr.set_index('DATE').resample('D').ffill().reset_index()\n",
    "\n",
    "def flatten_columns(df):\n",
    "    \"\"\"Flatten MultiIndex columns if necessary.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            '_'.join([str(c) for c in col if c]).strip()\n",
    "            for col in df.columns.values\n",
    "        ]\n",
    "    return df\n",
    "\n",
    "def safe_reset(df):\n",
    "    if df.index.name == 'Date':\n",
    "        return df.reset_index()\n",
    "    return df\n",
    "\n",
    "# --- Gold ---\n",
    "gold_feat = flatten_columns(gold_feat)\n",
    "gold_feat = safe_reset(gold_feat)\n",
    "merged_gold = pd.merge(\n",
    "    gold_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Oil (WTI) ---\n",
    "wti_feat = flatten_columns(wti_feat)\n",
    "wti_feat = safe_reset(wti_feat)\n",
    "merged_wti = pd.merge(\n",
    "    wti_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Wheat ---\n",
    "wheat_feat = flatten_columns(wheat_feat)\n",
    "wheat_feat = safe_reset(wheat_feat)\n",
    "merged_wheat = pd.merge(\n",
    "    wheat_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Quick checks ---\n",
    "print(\"Gold merged shape:\", merged_gold.shape)\n",
    "print(\"Oil merged shape:\", merged_wti.shape)\n",
    "print(\"Wheat merged shape:\", merged_wheat.shape)\n",
    "\n",
    "display(merged_gold.head())\n",
    "display(merged_wti.head())\n",
    "display(merged_wheat.head())\n"
   ],
   "id": "6e4e21462f06fd48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# quick check of saved files\n",
    "for fname in [\"gold_processed.csv\", \"wti_processed.csv\", \"wheat_processed.csv\"]:\n",
    "    print(fname, \"->\", os.path.exists(os.path.join(DATA_DIR,fname)))\n"
   ],
   "id": "b292813efcf22e21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "git add data/*.csv notebooks/01_data_collection.ipynb\n",
    "git commit -m \"Add data collection notebook + initial processed commodity files\"\n",
    "git push origin main\n"
   ],
   "id": "a1ffe62424f137e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 0: Project Overview\n",
    "__In this notebook, we collect raw data for our project:__\n",
    "- Commodity prices (gold, oil, wheat) via Yahoo Finance (yfinance).\n",
    "- Kaggle datasets: geopolitical risk index and global news.\n",
    "\n",
    "All raw files will be stored in the `data/` folder for consistency."
   ],
   "id": "6cd923e1d64c0d1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 01_data_collection\n",
    "Fetch commodity prices (gold, oil, wheat) and load Kaggle datasets (geopolitical risk, global news)"
   ],
   "id": "8fbf7ae9f1fc341e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 1: Install Dependencies (if missing)\n",
    "__We install required Python packages if not already available:__\n",
    "- `yfinance` for fetching financial data.\n",
    "- `kaggle` for downloading datasets from Kaggle.\n",
    "\n",
    "Uncomment and run the following lines only if packages are missing."
   ],
   "id": "6cfaba608ea76bf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# If you don't have yfinance or kaggle installed, run these:\n",
    " !pip install yfinance kaggle\n"
   ],
   "id": "b80b1fe2130fdcf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 2: Import Libraries and Set Paths\n",
    "__We import all the necessary libraries and configure global paths:__\n",
    "- `os` ‚Üí file system operations.\n",
    "- `pandas` / `numpy` ‚Üí data handling.\n",
    "- `yfinance` ‚Üí commodity price data.\n",
    "- `datetime` ‚Üí date management.\n",
    "\n",
    "We also define the root directory, create a `data/` folder if it doesn‚Äôt exist, and set our analysis date range."
   ],
   "id": "fc5234cac136c739"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:14:51.327970Z",
     "start_time": "2025-10-11T15:14:51.302434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Project root ---\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # notebook assumed in /notebooks\n",
    "print(f\"ROOT: {ROOT}\")\n",
    "\n",
    "# --- Data folders ---\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "MERGED_DIR = os.path.join(DATA_DIR, \"merged\")\n",
    "\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MERGED_DIR, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "\n",
    "# --- Ensure all exist ---\n",
    "for folder in [DATA_DIR, RAW_DIR, PROCESSED_DIR, MERGED_DIR]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(\"Data folders ready:\")\n",
    "for f in [RAW_DIR, PROCESSED_DIR, MERGED_DIR]:\n",
    "    print(\" -\", f)\n",
    "# choose date range\n",
    "START = \"1985-01-01\"\n",
    "END = None  # None -> yfinance takes up to today\n"
   ],
   "id": "1d979d0e139e450a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: C:\\Users\\taton\\PycharmProjects\\capstone-data-science\n",
      "ROOT: C:\\Users\\taton\\PycharmProjects\\capstone-data-science\n",
      "RAW_DIR: C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\raw\n",
      "PROCESSED_DIR: C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\processed\n",
      "Data folders ready:\n",
      " - C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\raw\n",
      " - C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\processed\n",
      " - C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\merged\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 3: Define Commodity Tickers and Fetch Function\n",
    "__We define the tickers for gold, WTI crude oil, and wheat futures.__\n",
    "- Each ticker corresponds to a Yahoo Finance symbol.\n",
    "- We then implement a helper function `fetch_save()` which:\n",
    "  1. Downloads the data from Yahoo Finance.\n",
    "  2. Adds daily returns and 5-day rolling volatility.\n",
    "  3. Saves the data as a CSV in the `data/` folder."
   ],
   "id": "70bdfc2fb8fd9bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:23:33.659257Z",
     "start_time": "2025-10-11T15:23:33.645675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tickers = {\n",
    "    \"Gold\": \"GC=F\",      # Gold futures\n",
    "    \"WTI\":  \"CL=F\",      # WTI crude oil future\n",
    "    \"Wheat\": \"ZW=F\"      # Wheat futures\n",
    "}\n",
    "def add_features(df, price_col=\"Close\"):\n",
    "    df = df.copy()\n",
    "    df[\"Return\"] = df[price_col].pct_change()\n",
    "    df[\"MA_5\"] = df[price_col].rolling(5).mean()\n",
    "    df[\"Vol_5\"] = df[\"Return\"].rolling(5).std()\n",
    "    return df\n",
    "\n",
    "def flatten_columns(df):\n",
    "    \"\"\"Flatten MultiIndex columns if present.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            '_'.join([str(c) for c in col if c]).strip()\n",
    "            for col in df.columns.values\n",
    "        ]\n",
    "    return df\n",
    "\n",
    "def fetch_save(ticker_symbol, shortname):\n",
    "    print(f\"Downloading {shortname} ({ticker_symbol}) ...\")\n",
    "    df = yf.download(ticker_symbol, start=START, end=END, progress=False, auto_adjust=True)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è Warning: empty dataframe for {shortname}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Save raw data\n",
    "    df = flatten_columns(df)\n",
    "    raw_path = os.path.join(RAW_DIR, f\"{shortname.lower()}_raw.csv\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df.to_csv(raw_path, index=False)\n",
    "    print(f\"‚úÖ Raw {shortname} data saved to {raw_path}\")\n",
    "\n",
    "    # Add features\n",
    "    df = add_features(df, price_col=\"Close\")\n",
    "\n",
    "    # Save processed data\n",
    "    processed_path = os.path.join(PROCESSED_DIR, f\"{shortname.lower()}_processed.csv\")\n",
    "    df.to_csv(processed_path, index=False)\n",
    "    print(f\"‚úÖ Processed {shortname} data saved to {processed_path}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ],
   "id": "5667f6f56214e1c5",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 4: Fetch and Save Commodity Data\n",
    "__We use the `fetch_save()` function to download and store data for:__\n",
    "- Gold futures\n",
    "- WTI crude oil futures\n",
    "- Wheat futures"
   ],
   "id": "eaa3a45516cb8754"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:23:40.247226Z",
     "start_time": "2025-10-11T15:23:38.317772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Run for all commodities ---\n",
    "df_gold = fetch_save(tickers[\"Gold\"], \"Gold\")\n",
    "df_wti = fetch_save(tickers[\"WTI\"], \"WTI\")\n",
    "df_wheat = fetch_save(tickers[\"Wheat\"], \"Wheat\")\n",
    "\n",
    "print(\"\\nüìÇ Raw data files:\", os.listdir(RAW_DIR))\n",
    "print(\"üìÇ Processed data files:\", os.listdir(PROCESSED_DIR))"
   ],
   "id": "c6b082b7f7a25dcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gold (GC=F) ...\n",
      "‚úÖ Raw Gold data saved to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\raw\\gold_raw.csv\n",
      "‚úÖ Processed Gold data saved to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\processed\\gold_processed.csv\n",
      "Downloading WTI (CL=F) ...\n",
      "‚úÖ Raw WTI data saved to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\raw\\wti_raw.csv\n",
      "‚úÖ Processed WTI data saved to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\processed\\wti_processed.csv\n",
      "Downloading Wheat (ZW=F) ...\n",
      "‚úÖ Raw Wheat data saved to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\raw\\wheat_raw.csv\n",
      "‚úÖ Processed Wheat data saved to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\processed\\wheat_processed.csv\n",
      "\n",
      "üìÇ Raw data files: ['gold_futures.csv', 'gold_futures_raw.csv', 'gold_raw.csv', 'wheat_futures.csv', 'wheat_raw.csv', 'wti_crude.csv', 'wti_raw.csv']\n",
      "üìÇ Processed data files: ['gold_processed.csv', 'wheat_processed.csv', 'wti_processed.csv']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 5: Quick Data Inspection\n",
    "__We verify that the downloaded datasets contain rows and preview the first few entries.__\n"
   ],
   "id": "3737bb8f507846a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:23:51.802861Z",
     "start_time": "2025-10-11T15:23:51.714217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, df in [(\"Gold\", df_gold), (\"WTI\", df_wti), (\"Wheat\", df_wheat)]:\n",
    "    print(name, \"rows:\", 0 if df is None else len(df))\n",
    "    display(df.head())\n"
   ],
   "id": "47b963fe278c02d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold rows: 6302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Price        Date       Close        High         Low        Open Volume  \\\n",
       "Ticker                   GC=F        GC=F        GC=F        GC=F   GC=F   \n",
       "0      2000-08-30  273.899994  273.899994  273.899994  273.899994      0   \n",
       "1      2000-08-31  278.299988  278.299988  274.799988  274.799988      0   \n",
       "2      2000-09-01  277.000000  277.000000  277.000000  277.000000      0   \n",
       "3      2000-09-05  275.799988  275.799988  275.799988  275.799988      2   \n",
       "4      2000-09-06  274.200012  274.200012  274.200012  274.200012      0   \n",
       "\n",
       "Price     Return        MA_5 Vol_5  \n",
       "Ticker                              \n",
       "0            NaN         NaN   NaN  \n",
       "1       0.016064         NaN   NaN  \n",
       "2      -0.004671         NaN   NaN  \n",
       "3      -0.004332         NaN   NaN  \n",
       "4      -0.005801  275.839996   NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>Vol_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>GC=F</th>\n",
       "      <th>GC=F</th>\n",
       "      <th>GC=F</th>\n",
       "      <th>GC=F</th>\n",
       "      <th>GC=F</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-30</td>\n",
       "      <td>273.899994</td>\n",
       "      <td>273.899994</td>\n",
       "      <td>273.899994</td>\n",
       "      <td>273.899994</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-08-31</td>\n",
       "      <td>278.299988</td>\n",
       "      <td>278.299988</td>\n",
       "      <td>274.799988</td>\n",
       "      <td>274.799988</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-09-01</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-09-05</td>\n",
       "      <td>275.799988</td>\n",
       "      <td>275.799988</td>\n",
       "      <td>275.799988</td>\n",
       "      <td>275.799988</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.004332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>274.200012</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005801</td>\n",
       "      <td>275.839996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTI rows: 6311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Price        Date      Close       High        Low       Open Volume  \\\n",
       "Ticker                  CL=F       CL=F       CL=F       CL=F   CL=F   \n",
       "0      2000-08-23  32.049999  32.799999  31.950001  31.950001  79385   \n",
       "1      2000-08-24  31.629999  32.240002  31.400000  31.900000  72978   \n",
       "2      2000-08-25  32.049999  32.099998  31.320000  31.700001  44601   \n",
       "3      2000-08-28  32.869999  32.919998  31.860001  32.040001  46770   \n",
       "4      2000-08-29  32.720001  33.029999  32.560001  32.820000  49131   \n",
       "\n",
       "Price     Return    MA_5 Vol_5  \n",
       "Ticker                          \n",
       "0            NaN     NaN   NaN  \n",
       "1      -0.013105     NaN   NaN  \n",
       "2       0.013279     NaN   NaN  \n",
       "3       0.025585     NaN   NaN  \n",
       "4      -0.004563  32.264   NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>Vol_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>CL=F</th>\n",
       "      <th>CL=F</th>\n",
       "      <th>CL=F</th>\n",
       "      <th>CL=F</th>\n",
       "      <th>CL=F</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-23</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>31.950001</td>\n",
       "      <td>31.950001</td>\n",
       "      <td>79385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-08-24</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>72978</td>\n",
       "      <td>-0.013105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>31.320000</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>44601</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-08-28</td>\n",
       "      <td>32.869999</td>\n",
       "      <td>32.919998</td>\n",
       "      <td>31.860001</td>\n",
       "      <td>32.040001</td>\n",
       "      <td>46770</td>\n",
       "      <td>0.025585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-08-29</td>\n",
       "      <td>32.720001</td>\n",
       "      <td>33.029999</td>\n",
       "      <td>32.560001</td>\n",
       "      <td>32.820000</td>\n",
       "      <td>49131</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>32.264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wheat rows: 6326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Price        Date   Close   High     Low    Open Volume    Return   MA_5 Vol_5\n",
       "Ticker               ZW=F   ZW=F    ZW=F    ZW=F   ZW=F                       \n",
       "0      2000-07-17  244.00  248.0  243.75  248.00   7233       NaN    NaN   NaN\n",
       "1      2000-07-18  241.25  247.5  241.00  244.25   6523 -0.011270    NaN   NaN\n",
       "2      2000-07-19  245.00  246.0  239.00  241.25   7136  0.015544    NaN   NaN\n",
       "3      2000-07-20  247.00  247.5  244.00  244.00   3792  0.008163    NaN   NaN\n",
       "4      2000-07-21  247.25  248.5  246.50  247.00   4380  0.001012  244.9   NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>Vol_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>ZW=F</th>\n",
       "      <th>ZW=F</th>\n",
       "      <th>ZW=F</th>\n",
       "      <th>ZW=F</th>\n",
       "      <th>ZW=F</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-07-17</td>\n",
       "      <td>244.00</td>\n",
       "      <td>248.0</td>\n",
       "      <td>243.75</td>\n",
       "      <td>248.00</td>\n",
       "      <td>7233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-07-18</td>\n",
       "      <td>241.25</td>\n",
       "      <td>247.5</td>\n",
       "      <td>241.00</td>\n",
       "      <td>244.25</td>\n",
       "      <td>6523</td>\n",
       "      <td>-0.011270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-07-19</td>\n",
       "      <td>245.00</td>\n",
       "      <td>246.0</td>\n",
       "      <td>239.00</td>\n",
       "      <td>241.25</td>\n",
       "      <td>7136</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-07-20</td>\n",
       "      <td>247.00</td>\n",
       "      <td>247.5</td>\n",
       "      <td>244.00</td>\n",
       "      <td>244.00</td>\n",
       "      <td>3792</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-07-21</td>\n",
       "      <td>247.25</td>\n",
       "      <td>248.5</td>\n",
       "      <td>246.50</td>\n",
       "      <td>247.00</td>\n",
       "      <td>4380</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>244.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 6: Download Kaggle Datasets\n",
    "__We now download external datasets from Kaggle for further analysis:__\n",
    "1. **Gold & Silver Price vs Geopolitical Risk Index**\n",
    "2. **Global News Dataset**\n",
    "3. **Gold Price Prediction (LSTM reference dataset)**\n",
    "\n",
    "‚ö†Ô∏è **Note:**\n",
    "- This requires you to have your Kaggle API key (`kaggle.json`) set up in `~/.kaggle/`.\n",
    "- These commands must be run in a notebook or shell with Kaggle configured."
   ],
   "id": "360666ba4560691c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:24:31.098338Z",
     "start_time": "2025-10-11T15:23:59.919437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Make sure we have a \"data\" directory\n",
    "os.makedirs(\"../../data\", exist_ok=True)\n",
    "\n",
    "# 1. Gold & Silver Price vs Geopolitical Risk Index\n",
    "!kaggle datasets download -d shreyanshdangi/gold-silver-price-vs-geopolitical-risk-19852025 -p data --unzip\n",
    "\n",
    "# 2. Global News Dataset\n",
    "!kaggle datasets download -d everydaycodings/global-news-dataset -p data --unzip\n",
    "\n",
    "# 3. Gold Price Prediction (LSTM reference dataset)\n",
    "!kaggle kernels pull farzadnekouei/gold-price-prediction-lstm-96-accuracy -p data/lstm_reference\n",
    "\n"
   ],
   "id": "d790a38b671f830f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/shreyanshdangi/gold-silver-price-vs-geopolitical-risk-19852025\n",
      "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
      "Downloading gold-silver-price-vs-geopolitical-risk-19852025.zip to data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/745k [00:00<?, ?B/s]\n",
      "100%|##########| 745k/745k [00:00<00:00, 291MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/everydaycodings/global-news-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading global-news-dataset.zip to data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/400M [00:00<?, ?B/s]\n",
      " 18%|#8        | 72.0M/400M [00:00<00:00, 755MB/s]\n",
      " 36%|###6      | 144M/400M [00:00<00:00, 611MB/s] \n",
      " 51%|#####1    | 204M/400M [00:00<00:00, 555MB/s]\n",
      " 65%|######5   | 260M/400M [00:00<00:00, 553MB/s]\n",
      " 79%|#######8  | 314M/400M [00:00<00:00, 537MB/s]\n",
      " 92%|#########1| 366M/400M [00:00<00:00, 531MB/s]\n",
      "100%|##########| 400M/400M [00:00<00:00, 544MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code downloaded to data/lstm_reference\\gold-price-prediction-lstm-96-accuracy.ipynb\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 7: Inspect Downloaded Files & Load External Datasets\n",
    "__We:__\n",
    "1. List the contents of the `data/` directory (to check Kaggle download results).\n",
    "2. Attempt to load:\n",
    "   - Geopolitical Risk (GPR) dataset\n",
    "   - Global News dataset\n",
    "\n",
    "‚ö†Ô∏è Note: Filenames may differ, so adapt accordingly."
   ],
   "id": "dce73371b5d60d2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:35:38.469256Z",
     "start_time": "2025-10-11T15:35:31.722308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Load your original datasets (raw) ---\n",
    "gpr_path = os.path.join(RAW_DIR, \"All_Historical_Data_Separately\", \"Geopolitical Risk Index Daily.csv\")\n",
    "news_path = os.path.join(RAW_DIR, \"Global News dataset\", \"data.csv\")\n",
    "\n",
    "try:\n",
    "    gpr = pd.read_csv(gpr_path)\n",
    "    print(\"‚úÖ GPR dataset loaded:\", gpr.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è GPR dataset not found at:\", gpr_path)\n",
    "    gpr = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    global_news = pd.read_csv(news_path)\n",
    "    print(\"‚úÖ Global news dataset loaded:\", global_news.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Global News dataset not found at:\", news_path)\n",
    "    global_news = pd.DataFrame()\n",
    "\n",
    "# --- Quick sanity checks ---\n",
    "if not gpr.empty:\n",
    "    print(\"\\nüìä GPR preview:\")\n",
    "    print(gpr.head(3))\n",
    "\n",
    "if not global_news.empty:\n",
    "    print(\"\\nüì∞ Global news preview:\")\n",
    "    print(global_news.head(3))"
   ],
   "id": "3cdbad6bd8423e89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPR dataset loaded: (14861, 5)\n",
      "‚úÖ Global news dataset loaded: (105375, 12)\n",
      "\n",
      "üìä GPR preview:\n",
      "         DATE    GPRD GPRD_ACT  GPRD_THREAT EVENT\n",
      "0  01-01-1985  230.04   275.20       153.03   NaN\n",
      "1  02-01-1985  115.68   146.77        87.44   NaN\n",
      "2  03-01-1985   97.43   158.94        29.46   NaN\n",
      "\n",
      "üì∞ Global news preview:\n",
      "   article_id source_id                   source_name  \\\n",
      "0       89541       NaN  International Business Times   \n",
      "1       89542       NaN                    Prtimes.jp   \n",
      "2       89543       NaN                      VOA News   \n",
      "\n",
      "                                       author  \\\n",
      "0                              Paavan MATHEMA   \n",
      "1                                         NaN   \n",
      "2  webdesk@voanews.com (Agence France-Presse)   \n",
      "\n",
      "                                               title  \\\n",
      "0  UN Chief Urges World To 'Stop The Madness' Of ...   \n",
      "1              RANDEBOO„Çà„Çä„ÉØ„É≥„É©„É≥„ÇØ‰∏ä„ÅÆÂ§ß‰∫∫„Å£„ÅΩ„Åï„ÅåÊºÇ„ÅÜ„Éã„ÉÉ„Éà„Å®„Éô„Çπ„Éà„ÅåÊñ∞ÁôªÂ†¥„ÄÇ   \n",
      "2  UN Chief Urges World to 'Stop the Madness' of ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  UN Secretary-General Antonio Guterres urged th...   \n",
      "1  [Ê†™Âºè‰ºöÁ§æAiner]\\nRANDEBOOÔºà„É©„É≥„Éá„Éñ„ÉºÔºâ„Åß„ÅØ2023Âπ¥7Êúà18Êó•(ÁÅ´)„Çà„ÇäÂÖ¨...   \n",
      "2  UN Secretary-General Antonio Guterres urged th...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.ibtimes.com/un-chief-urges-world-s...   \n",
      "1  https://prtimes.jp/main/html/rd/p/000000147.00...   \n",
      "2  https://www.voanews.com/a/un-chief-urges-world...   \n",
      "\n",
      "                                        url_to_image  \\\n",
      "0  https://d.ibtimes.com/en/full/4496078/nepals-g...   \n",
      "1  https://prtimes.jp/i/32220/147/ogp/d32220-147-...   \n",
      "2  https://gdb.voanews.com/01000000-0a00-0242-60f...   \n",
      "\n",
      "                 published_at  \\\n",
      "0  2023-10-30 10:12:35.000000   \n",
      "1  2023-10-06 04:40:02.000000   \n",
      "2  2023-10-30 10:53:30.000000   \n",
      "\n",
      "                                             content category  \\\n",
      "0  UN Secretary-General Antonio Guterres urged th...    Nepal   \n",
      "1  RANDEBOO2023718()WEB2023 Autumn Winter \\n\"Nepa...    Nepal   \n",
      "2  Kathmandu, Nepal ¬†UN Secretary-General Antonio...    Nepal   \n",
      "\n",
      "                                        full_content  \n",
      "0  UN Secretary-General Antonio Guterres urged th...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 8: Add Basic Features to Commodity Prices\n",
    "__We define a helper function `add_basic_features()` that:__\n",
    "- Parses the `Date` column\n",
    "- Ensures chronological order\n",
    "- Chooses the correct price column (`Adj Close` if available, otherwise `Close`)\n",
    "- Computes daily returns, 5-day moving average (MA_5), and 5-day rolling volatility (Vol_5)\n",
    "\n",
    "Then we apply it to Gold, WTI crude, and Wheat, and save the processed results to CSV.\n",
    "\n",
    "Feature Engineering for Commodity Prices\n",
    "__We:__\n",
    "1. Define `add_basic_features()` to compute:\n",
    "   - Returns (`pct_change`)\n",
    "   - 5-day moving average (`MA_5`)\n",
    "   - 5-day volatility (`Vol_5`)\n",
    "2. Apply it to Gold, WTI, and Wheat datasets.\n",
    "3. Save processed outputs as `*_processed.csv`."
   ],
   "id": "8fd80e63bd08ea8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:53:14.669685Z",
     "start_time": "2025-10-11T15:53:14.418349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_basic_features(df):\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df.sort_values('Date', inplace=True)\n",
    "\n",
    "    # (fix) removed ineffective: df.set_index('Date', inplace=False)\n",
    "    price_col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
    "    df[price_col] = df[price_col].astype(float)\n",
    "\n",
    "    df['Return'] = df[price_col].pct_change()\n",
    "    df['MA_5'] = df[price_col].rolling(window=5).mean()\n",
    "    df['Vol_5'] = df['Return'].rolling(window=5).std()\n",
    "\n",
    "gold_feat = add_basic_features(df_gold) if not df_gold.empty else pd.DataFrame()\n",
    "wti_feat  = add_basic_features(df_wti) if not df_wti.empty else pd.DataFrame()\n",
    "wheat_feat= add_basic_features(df_wheat) if not df_wheat.empty else pd.DataFrame()\n",
    "\n",
    "## --- Save processed versions ---\n",
    "gold_feat.to_csv(os.path.join(PROCESSED_DIR, \"gold_processed.csv\"), index=False)\n",
    "wti_feat.to_csv(os.path.join(PROCESSED_DIR, \"wti_processed.csv\"), index=False)\n",
    "wheat_feat.to_csv(os.path.join(PROCESSED_DIR, \"wheat_processed.csv\"), index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved processed files to {PROCESSED_DIR}\")\n",
    "print(\"Processed files:\", os.listdir(PROCESSED_DIR))\n",
    "\n",
    "print(\"GPR preview:\" if not gpr.empty else \"‚ö†Ô∏è GPR empty\")\n",
    "print(gpr.head())\n",
    "\n"
   ],
   "id": "d684bd9c892b722c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved processed files to C:\\Users\\taton\\PycharmProjects\\capstone-data-science\\data\\processed\n",
      "Processed files: ['gold_processed.csv', 'wheat_processed.csv', 'wti_processed.csv']\n",
      "GPR preview:\n",
      "         DATE    GPRD GPRD_ACT  GPRD_THREAT EVENT\n",
      "0  01-01-1985  230.04   275.20       153.03   NaN\n",
      "1  02-01-1985  115.68   146.77        87.44   NaN\n",
      "2  03-01-1985   97.43   158.94        29.46   NaN\n",
      "3  04-01-1985  157.37   156.88       157.03   NaN\n",
      "4  05-01-1985   81.36    92.70        77.32   NaN\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 11: Quick Check of Saved Processed Files\n",
    "__We check if our processed CSVs were successfully created and stored in `data/`.__"
   ],
   "id": "5c4e9534e2d59c07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T21:00:54.447758Z",
     "start_time": "2025-10-03T21:00:54.424789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quick check of saved files\n",
    "for fname in [\"gold_processed.csv\", \"wti_processed.csv\", \"wheat_processed.csv\"]:\n",
    "    print(fname, \"->\", os.path.exists(os.path.join(DATA_DIR,fname)))\n"
   ],
   "id": "b292813efcf22e21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_processed.csv -> True\n",
      "wti_processed.csv -> True\n",
      "wheat_processed.csv -> True\n",
      "Price        Date       Close        High         Low        Open Volume  \\\n",
      "Ticker                   GC=F        GC=F        GC=F        GC=F   GC=F   \n",
      "0      2000-08-30  273.899994  273.899994  273.899994  273.899994      0   \n",
      "1      2000-08-31  278.299988  278.299988  274.799988  274.799988      0   \n",
      "2      2000-09-01  277.000000  277.000000  277.000000  277.000000      0   \n",
      "3      2000-09-05  275.799988  275.799988  275.799988  275.799988      2   \n",
      "4      2000-09-06  274.200012  274.200012  274.200012  274.200012      0   \n",
      "\n",
      "Price  Return Vol_5        MA_5  \n",
      "Ticker                           \n",
      "0         NaN   NaN         NaN  \n",
      "1         NaN   NaN         NaN  \n",
      "2         NaN   NaN         NaN  \n",
      "3         NaN   NaN         NaN  \n",
      "4         NaN   NaN  275.839996  \n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 12: Save Notebook & Commit to Git\n",
    "__Now that we have processed datasets and a working pipeline, we commit our notebook + CSV files to Git for version control.__\n",
    "\n",
    "‚ö†Ô∏è Run these commands in the **terminal**, not inside the notebook."
   ],
   "id": "dc384c0d82538d50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "git add data/*.csv notebooks/01_data_collection.ipynb\n",
    "git commit -m \"Add data collection notebook + initial processed commodity files\"\n",
    "git push origin main\n"
   ],
   "id": "a1ffe62424f137e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 17: Load Kaggle Datasets into DataFrames\n",
    "__We:__\n",
    "1. List available files in `data/` to adapt filenames if needed.\n",
    "2. Load **Geopolitical Risk Index** and **Global News** datasets.\n",
    "3. Provide fallback placeholders (`None`) if datasets are missing."
   ],
   "id": "be453b3926b38e17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:50:40.338842Z",
     "start_time": "2025-10-11T15:50:40.271652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(gold_feat.index)\n",
    "print(gold_feat.columns)\n",
    "print(gold_feat['Date'].dtype)\n",
    "print(gpr_daily['DATE'].dtype)"
   ],
   "id": "136921218a9cc074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=6302, step=1)\n",
      "MultiIndex([(  'Date',     ''),\n",
      "            ( 'Close', 'GC=F'),\n",
      "            (  'High', 'GC=F'),\n",
      "            (   'Low', 'GC=F'),\n",
      "            (  'Open', 'GC=F'),\n",
      "            ('Volume', 'GC=F'),\n",
      "            ('Return',     ''),\n",
      "            (  'MA_5',     ''),\n",
      "            ( 'Vol_5',     '')],\n",
      "           names=['Price', 'Ticker'])\n",
      "datetime64[ns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gpr_daily' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(gold_feat.columns)\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(gold_feat[\u001B[33m'\u001B[39m\u001B[33mDate\u001B[39m\u001B[33m'\u001B[39m].dtype)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mgpr_daily\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mDATE\u001B[39m\u001B[33m'\u001B[39m].dtype)\n",
      "\u001B[31mNameError\u001B[39m: name 'gpr_daily' is not defined"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T15:53:26.321595Z",
     "start_time": "2025-10-11T15:53:26.313054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Gold columns:\", gold_feat.columns.tolist())\n",
    "print(\"WTI columns:\", wti_feat.columns.tolist())\n",
    "print(\"Wheat columns:\", wheat_feat.columns.tolist())"
   ],
   "id": "25900f71339ed3c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold columns: ['Date', 'Close_GC=F', 'High_GC=F', 'Low_GC=F', 'Open_GC=F', 'Volume_GC=F', 'Return', 'MA_5', 'Vol_5']\n",
      "WTI columns: ['Date', 'Close_CL=F', 'High_CL=F', 'Low_CL=F', 'Open_CL=F', 'Volume_CL=F', 'Return', 'MA_5', 'Vol_5']\n",
      "Wheat columns: ['Date', 'Close_ZW=F', 'High_ZW=F', 'Low_ZW=F', 'Open_ZW=F', 'Volume_ZW=F', 'Return', 'MA_5', 'Vol_5']\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 19: Prepare GPR dataset\n",
    "__We:__\n",
    "Convert GPR `DATE` column to datetime and resample daily.\n"
   ],
   "id": "d0725d2f84696d79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T16:03:11.633771Z",
     "start_time": "2025-10-11T16:03:11.154860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Prepare GPR dataset ---\n",
    "gpr_path = os.path.join(RAW_DIR, \"Geopolitical Risk Index Daily.csv\")\n",
    "gpr = pd.read_csv(gpr_path)\n",
    "gpr['DATE'] = pd.to_datetime(gpr['DATE'])\n",
    "gpr_daily = gpr.set_index('DATE').resample('D').ffill().reset_index()\n",
    "gpr_daily = gpr_daily[['DATE', 'GPRD', 'GPRD_THREAT', 'EVENT']]\n",
    "print(\"GPR prepared shape:\", gpr_daily.shape)\n",
    "\n",
    "\n",
    "def prepare_features(df, price_col=\"Adj_Close\", name=\"Commodity\"):\n",
    "    df = df.copy()\n",
    "    if price_col not in df.columns:\n",
    "        # fallback if only \"Close\" exists\n",
    "        price_col = \"Close\" if \"Close\" in df.columns else df.columns[1]\n",
    "        print(f\"‚ö†Ô∏è {name}: '{price_col}' used instead.\")\n",
    "    df[\"Return\"] = df[price_col].pct_change()\n",
    "    df[\"MA_5\"] = df[price_col].rolling(5).mean()\n",
    "    df[\"Vol_5\"] = df[\"Return\"].rolling(5).std()\n",
    "    df = df.dropna(subset=[price_col, \"Return\", \"MA_5\", \"Vol_5\"]).reset_index(drop=True)\n",
    "    print(f\"{name} features prepared:\", df.shape)\n",
    "    return df\n",
    "\n",
    "# def prepare_feat(df, name):\n",
    "#     \"\"\"Make sure features exist and drop NaN rows caused by pct_change/rolling.\"\"\"\n",
    "#     df = flatten_columns(df)\n",
    "#     df = safe_reset(df)# Find best matches\n",
    "#     possible_cols = df.columns.tolist()\n",
    "#\n",
    "#     date_col = 'Date' if 'Date' in possible_cols else df.columns[0]\n",
    "#     adj_col = [c for c in possible_cols if 'Adj' in c or 'Close' in c][0]\n",
    "#     return_col = [c for c in possible_cols if 'Return' in c][0]\n",
    "#     ma_col = [c for c in possible_cols if 'MA' in c][0]\n",
    "#     vol_col = [c for c in possible_cols if 'Vol' in c][0]\n",
    "#\n",
    "#     keep_cols = [date_col, adj_col, return_col, ma_col, vol_col]\n",
    "#     df = df[keep_cols].dropna().reset_index(drop=True)\n",
    "#\n",
    "#     # Rename columns for consistency\n",
    "#     df.columns = ['Date', 'Adj_Close', 'Return', 'MA_5', 'Vol_5']\n",
    "#\n",
    "#     print(f\"{name} after feature prep:\", df.shape)\n",
    "#     return df\n",
    "\n",
    "gold_feat = prepare_features(gold_feat, price_col=\"Close_GC=F\", name=\"Gold\")\n",
    "\n",
    "wti_feat = prepare_features(wti_feat, price_col=\"Close_CL=F\", name=\"WTI\")\n",
    "\n",
    "wheat_feat = prepare_features(wheat_feat, price_col=\"Close_ZW=F\", name=\"Wheat\")\n",
    "# --- Save processed features ---\n",
    "gold_feat.to_csv(os.path.join(PROCESSED_DIR, \"gold_processed.csv\"), index=False)\n",
    "wti_feat.to_csv(os.path.join(PROCESSED_DIR, \"wti_processed.csv\"), index=False)\n",
    "wheat_feat.to_csv(os.path.join(PROCESSED_DIR, \"wheat_processed.csv\"), index=False)\n",
    "print(\"‚úÖ Processed CSVs saved to:\", PROCESSED_DIR)"
   ],
   "id": "b5e1fb3eed3958f3",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\taton\\\\PycharmProjects\\\\capstone-data-science\\\\data\\\\raw\\\\Geopolitical Risk Index Daily.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[46]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# --- Prepare GPR dataset ---\u001B[39;00m\n\u001B[32m      2\u001B[39m gpr_path = os.path.join(RAW_DIR, \u001B[33m\"\u001B[39m\u001B[33mGeopolitical Risk Index Daily.csv\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m gpr = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgpr_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m gpr[\u001B[33m'\u001B[39m\u001B[33mDATE\u001B[39m\u001B[33m'\u001B[39m] = pd.to_datetime(gpr[\u001B[33m'\u001B[39m\u001B[33mDATE\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m      5\u001B[39m gpr_daily = gpr.set_index(\u001B[33m'\u001B[39m\u001B[33mDATE\u001B[39m\u001B[33m'\u001B[39m).resample(\u001B[33m'\u001B[39m\u001B[33mD\u001B[39m\u001B[33m'\u001B[39m).ffill().reset_index()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Python\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\taton\\\\PycharmProjects\\\\capstone-data-science\\\\data\\\\raw\\\\Geopolitical Risk Index Daily.csv'"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 20: Merge All Commodities with Geopolitical Risk Index\n",
    "__We:__\n",
    "1. Define utility functions:\n",
    "   - `flatten_columns()` ‚Üí handle MultiIndex columns.\n",
    "   - `safe_reset()` ‚Üí reset index if needed.\n",
    "2. Apply preprocessing to Gold, WTI, and Wheat.\n",
    "3. Merge each with daily GPR data.\n",
    "4. Display merged dataset previews."
   ],
   "id": "63e3dd8e2a49b6a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T16:01:39.563375Z",
     "start_time": "2025-10-11T16:01:39.504345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flatten_columns(df):\n",
    "    \"\"\"Flatten MultiIndex columns if necessary.\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [\n",
    "            '_'.join([str(c) for c in col if c]).strip()\n",
    "            for col in df.columns.values\n",
    "        ]\n",
    "    if df.index.name == 'Date':\n",
    "        return df.reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# --- Gold ---\n",
    "gold_feat = flatten_columns(gold_feat)\n",
    "merged_gold = pd.merge(\n",
    "    gold_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Oil (WTI) ---\n",
    "wti_feat = flatten_columns(wti_feat)\n",
    "merged_wti = pd.merge(\n",
    "    wti_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Wheat ---\n",
    "wheat_feat = flatten_columns(wheat_feat)\n",
    "merged_wheat = pd.merge(\n",
    "    wheat_feat,\n",
    "    gpr_daily,\n",
    "    left_on='Date',\n",
    "    right_on='DATE',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- Quick checks ---\n",
    "print(\"Gold merged shape:\", merged_gold.shape)\n",
    "print(\"Oil merged shape:\", merged_wti.shape)\n",
    "print(\"Wheat merged shape:\", merged_wheat.shape)\n",
    "\n",
    "display(merged_gold.head())\n",
    "display(merged_wti.head())\n",
    "display(merged_wheat.head())\n"
   ],
   "id": "4ace158a23b0df7d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpr_daily' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[44]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# --- Gold ---\u001B[39;00m\n\u001B[32m     15\u001B[39m gold_feat = flatten_columns(gold_feat)\n\u001B[32m     16\u001B[39m merged_gold = pd.merge(\n\u001B[32m     17\u001B[39m     gold_feat,\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     \u001B[43mgpr_daily\u001B[49m,\n\u001B[32m     19\u001B[39m     left_on=\u001B[33m'\u001B[39m\u001B[33mDate\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     20\u001B[39m     right_on=\u001B[33m'\u001B[39m\u001B[33mDATE\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     21\u001B[39m     how=\u001B[33m'\u001B[39m\u001B[33mleft\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     22\u001B[39m )\n\u001B[32m     24\u001B[39m \u001B[38;5;66;03m# --- Oil (WTI) ---\u001B[39;00m\n\u001B[32m     25\u001B[39m wti_feat = flatten_columns(wti_feat)\n",
      "\u001B[31mNameError\u001B[39m: name 'gpr_daily' is not defined"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 21 ‚Äî Save merged datasets & Quick check of saved files (Notebook)",
   "id": "3af3187ac1f1e3c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T21:09:21.045990Z",
     "start_time": "2025-10-03T21:09:20.595637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_gold.to_csv(os.path.join(DATA_DIR, \"gold_merged.csv\"), index=False)\n",
    "merged_wti.to_csv(os.path.join(DATA_DIR, \"wti_merged.csv\"), index=False)\n",
    "merged_wheat.to_csv(os.path.join(DATA_DIR, \"wheat_merged.csv\"), index=False)\n",
    "\n",
    "print(\"Merged datasets saved in:\", DATA_DIR)\n",
    "# Quick check of saved processed files\n",
    "for fname in [\"gold_processed.csv\", \"wti_processed.csv\", \"wheat_processed.csv\"]:\n",
    "    exists = os.path.exists(os.path.join(DATA_DIR, fname))\n",
    "    print(f\"{fname} -> {'‚úÖ exists' if exists else '‚ùå missing'}\")"
   ],
   "id": "4b62676d8e32ec58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged datasets saved in: data\n",
      "gold_processed.csv -> ‚úÖ exists\n",
      "wti_processed.csv -> ‚úÖ exists\n",
      "wheat_processed.csv -> ‚úÖ exists\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 22 ‚Äî Save to Git (Terminal, not notebook)",
   "id": "92b6e63f0b530899"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:22:15.255539Z",
     "start_time": "2025-09-26T21:22:15.206139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "git add notebooks/01_data_collection.ipynb notebooks/notebooks/data/*.csv .gitignore\n",
    "git commit -m \"Add data collection notebook + initial processed commodity files\"\n",
    "git push origin main\n"
   ],
   "id": "ca7f092d9c84c740",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (495343877.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[68]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mgit add notebooks/notebooks/01_data_collection.ipynb notebooks/notebooks/data/*.csv .gitignore\u001B[39m\n                                  ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m invalid decimal literal\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T21:12:50.743567Z",
     "start_time": "2025-10-03T21:12:50.614134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(gold_feat[['Return', 'Vol_5']].info())\n",
    "print(gold_feat[['Return', 'Vol_5']].head())\n"
   ],
   "id": "20a6955f2294db8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6288 entries, 0 to 6287\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Return  0 non-null      float64\n",
      " 1   Vol_5   0 non-null      float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 98.4 KB\n",
      "None\n",
      "   Return  Vol_5\n",
      "0     NaN    NaN\n",
      "1     NaN    NaN\n",
      "2     NaN    NaN\n",
      "3     NaN    NaN\n",
      "4     NaN    NaN\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T21:13:20.455199Z",
     "start_time": "2025-10-03T21:13:20.440261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(merged_gold.columns)\n",
    "print(merged_gold[['Return', 'Vol_5']].head())"
   ],
   "id": "4db817e38922691e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Close_GC=F', 'High_GC=F', 'Low_GC=F', 'Open_GC=F',\n",
      "       'Volume_GC=F', 'Return', 'Vol_5', 'MA_5', 'DATE', 'GPRD', 'GPRD_THREAT',\n",
      "       'EVENT'],\n",
      "      dtype='object')\n",
      "   Return  Vol_5\n",
      "0     NaN    NaN\n",
      "1     NaN    NaN\n",
      "2     NaN    NaN\n",
      "3     NaN    NaN\n",
      "4     NaN    NaN\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7481e6fdf111f539"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
